{"title":"Matching and Subclassification","markdown":{"yaml":{"title":"Matching and Subclassification","linktitle":"Matching and Subclassification","date":"2022-10-01","output":{"blogdown::html_page":{"toc":true}},"menu":{"example":{"parent":"Toolbox","weight":7}},"type":"docs","editor_options":{"chunk_output_type":"console"}},"headingText":"custom ggplot theme","containsRefs":false,"markdown":"\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(fig.width = 6, fig.asp = 0.618, fig.align = \"center\", fig.retina = 3, out.width = \"75%\")\nset.seed(11)\noptions(\"digits\" = 2, \"width\" = 150)\noptions(dplyr.summarise.inform = FALSE)\n\n# colors from TUHH brand identitiy\ntuhh_colors <- c(\"#D0D0CE\", \"#00C1D4\", \"#FF4F4F\", \"#5AFFC5\",\n                 \"#FFDE36\", \"#143BFF\", \"#FF7E15\", \"#FFAEA2\")\n\n# initialise theme\ncds_theme <- ggthemr::define_palette(\n  swatch = tuhh_colors,\n  gradient = c(lower = \"#FFAEA2\", upper = \"#00C1D4\"),\n  #background = \"#1C1C1C\",\n  background = \"#011627\",\n  line = c(\"#FFFFFF\", \"#FFFFFF\"),\n  text = c(\"#FFFFFF\", \"#FFFFFF\"),\n  gridline = c(\"#D0D0CE\", \"#D0D0CE\")\n)\n\n# set theme\nggthemr::ggthemr(cds_theme, type = \"outer\")\n\n# source custom DAG theme\nsource(\"../../code/dag_theme.R\")\n```\n\n```{r warning=FALSE, message=FALSE}\nlibrary(tidyverse)\nlibrary(ggdag)\nlibrary(dagitty)\n```\n\n# Problem\n\nAlmost always, the problem we are trying to solve in causal inference relates to the fundamental problem of causal inference, the fact that we cannot observe two states for one particular observation unit, e.g. we cannot see how a person's health status changes after taking a specific drug and after not taking the same drug. Consequently, we cannot know the individual treatment effect.\n\nThus, we said we can make use of averages and try to estimate the average treatment effect by taking the difference between a group of treated observation units and a group of untreated observation units. Written in a formula, we can present it as\n\n$$\nATE = E[Y(1)| D = 1] - E[Y(0) | D = 0] \n$$\n\nAssuming that individuals (or other kinds of observation units) were randomly assigned for example to take the drug, then this result gives us exactly what we want. It compares the outcomes of groups under treatment with groups not under treatment.\n\nBut the estimate hinges on the assumption that both groups are comparable, formally $E[Y(0)|D=0] = E[Y(1)|D=0]$, which we cannot test but in a randomized setting we have good reason to believe it to be true. Under these circumstances, average treatment effect ($ATE$) and the average treatment effect on the treated ($ATT$) are equal.\n\nHowever, if there are in fact underlying group differences because the treatment assignment was not randomized and e.g. individuals were able to choose their treatment, we are not measuring the estimate that we are interested in. Then, the difference between $ATE$ and $ATT$ is what we call *selection bias*, an unmeasured factor representing systematic bias:\n\n$$\nATE = ATT + \\text{selection bias}\n$$\n\nGraphically, we can show an example of when the naive estimate would fail.\n\n```{r include=FALSE}\nconfounder <- 'dag {\nD [exposure,pos=\"0.000,0.000\"]\nY [outcome,pos=\"2.000,0.000\"]\nZ [pos=\"1.000,1.000\"]\nZ -> D\nZ -> Y\nD -> Y\n}'\nggdag(confounder) + theme_dag()\n```\n\nBy now, you might recognize what kind of problem the DAG depicts: confounding. A variable $Z$ confounds the relationship between $X$ and $Y$ and to estimate the causal effect of $X$ on $Y$, we need to close the backdoor path of $X$ to $Y$ via $Z$.\n\n# Intuition\n\nOne of the options to close it is **matching**, which covers any method attempting to equate or balance the distribution of covariates in treatment and control group. Simply put, the goal of matching is to compare apple to apples and post treatment make treatment and control group as similar as possible (of course, except for the treatment value).\n\nIn a way, matching is an alternative to using regression to close backdoors and neither is better or worse, in fact, they can even be combined. But for now, let us focus on matching and understand what it really it is, what kind of matching methods are popular and how they can be applied in `R`.\n\nLet us assume you would like to study a phenomena and only have observational data that looks like this. $Z$ is a covariate, $Y$ is the outcome and the color of the data points shows if a unit has been treated or not. From the first glance you can already see that the data does not look as if you would expect in a randomized experiment. For values of $Z$ in the middle range, there are both treated and untreated cases, but for values at the lower and upper range there are only untreated cases. That is an indication that $Z$ confounds the relationship between $D$ and $Y$.\n\n!!! Change text to application (education) or own example\n\n```{r}\n# Observations both treated and control (mid education)\nmatched_stuff <- tibble(education = rnorm(50, 20, 3)) %>% \n  mutate(outcome = 15 + education * rnorm(n(), -0.2, 0.05), \n         treatment = as.logical(rbinom(n(), 1, 0.5)),\n         type = \"Matched\")\n# Observations control (low education)\nunmatched_stuff_low <- tibble(education = rnorm(20, 12, 2),\n                          outcome = rnorm(20, 5, 2),\n                          treatment = FALSE, \n                          type = \"Unmatched\")\n# Observations control (high education)\nunmatched_stuff_high <- tibble(education = rnorm(5, 28, 1),\n                               outcome = rnorm(5, 5, 0.5),\n                               treatment = FALSE,\n                               type = \"Unmatched\")\n# All observations\nall_data <- bind_rows(matched_stuff, \n                      unmatched_stuff_low,\n                      unmatched_stuff_high) %>%\n  mutate(treatment = factor(treatment, \n                            labels = c(\"Untreated\", \"Treated\")))\n# Part of data that has matches (with factor treatment)\nmatched_stuff_real <- filter(all_data, type == \"Matched\")\n# Wrong model\nmodel_wrong <-\n  lm(outcome ~ education + treatment, data = all_data) %>% \n  broom::tidy()\n# Wrong model with square term\nmodel_wrong1 <- lm(outcome ~ education + treatment + I(education^2), \n                   data = all_data)\nmodel_wrong1_fitted <-\n  expand_grid(education = seq(8, 30, 0.1),\n              treatment = c(\"Treated\", \"Untreated\")) %>% \n  broom::augment(model_wrong1, newdata = .)\n# Better model\nmodel_better <- lm(outcome ~ education + treatment, data = matched_stuff_real) %>% \n  broom::tidy()\n# Better model with square term\nmodel_better1 <- lm(outcome ~ education + treatment + I(education^2), data = matched_stuff_real)\nmodel_better1_fitted <- expand_grid(education = seq(8, 30, 0.1),\n                                    treatment = c(\"Treated\", \"Untreated\")) %>% \n  broom::augment(model_better1, newdata = .)\n```\n\n```{r echo=FALSE}\n# Plot all data points\nggplot(all_data, aes(x = education, y = outcome, color = treatment)) +\n  geom_point(size = 5, pch = 19, alpha = .8) +\n  labs(x = \"Education\", y = \"Outcome\") +\n  coord_cartesian(xlim = c(8, 30), ylim = c(0, 15)) +\n  theme(legend.position = \"bottom\",\n        legend.margin = margin(t = 0, b = 0))\n```\n\nWhen we plot a line through all blue and red points, respectively and check the difference between the two lines, we see that there is substantial difference between both groups. This difference is what we would get when we run a regression on all points. It indicates a positive treatment effect.\n\n```{r echo=FALSE}\n# Plot regression lines for both treatment and control (all data)\nggplot(all_data, aes(x = education, y = outcome, color = treatment)) +\n  geom_point(size = 5, pch = 19, alpha = .8) +\n  geom_abline(slope = filter(model_wrong, term == \"education\")$estimate, \n              intercept = filter(model_wrong, term == \"(Intercept)\")$estimate,\n              color = ggthemr::swatch()[2], size = 0.75) +\n  geom_abline(slope = filter(model_wrong, term == \"education\")$estimate, \n              intercept = filter(model_wrong, term == \"(Intercept)\")$estimate +\n                filter(model_wrong, term == \"treatmentTreated\")$estimate,\n              color = ggthemr::swatch()[3], size = 0.75) +\n  labs(x = \"Education\", y = \"Outcome\") +\n  coord_cartesian(xlim = c(8, 30), ylim = c(0, 15)) +\n  theme(legend.position = \"bottom\",\n        legend.margin = margin(t = 0, b = 0))\n```\n\nHowever, the lines clearly don't fit the data very well because there does not seem to be a linear relationship. To account for non-linearities, you can introduce e.g. square terms to the regression, here $Z^2$. Then, the fit improves, in particular for the untreated data points. But what happened to the treatment effect? Now there is negative treatment effect smaller in magnitude than the previous positive treatment effect. We already see that the estimate is highly dependent on the choice of our particular model. This is why we should always put a lot of consideration into choosing the right model (which is not necessarily the one with the largest or desired treatment effect).\n\n```{r echo=FALSE}\n# Plot regression lines for linear and square (all data)\nggplot(all_data, aes(x = education, y = outcome, fill = treatment, color = treatment)) +\n  geom_point(size = 5, pch = 19, alpha = .8) +\n  geom_abline(slope = filter(model_wrong, term == \"education\")$estimate, \n              intercept = filter(model_wrong, term == \"(Intercept)\")$estimate,\n              color = ggthemr::swatch()[2], size = 0.75) +\n  geom_abline(slope = filter(model_wrong, term == \"education\")$estimate, \n              intercept = filter(model_wrong, term == \"(Intercept)\")$estimate +\n                filter(model_wrong, term == \"treatmentTreated\")$estimate,\n              color = ggthemr::swatch()[3], size = 0.75) +\n  geom_line(data = model_wrong1_fitted, \n            aes(x = education, y = .fitted, color = treatment),\n            size = 0.75) +\n  labs(x = \"Education\", y = \"Outcome\") +\n  coord_cartesian(xlim = c(8, 30), ylim = c(0, 15)) +\n  theme(legend.position = \"bottom\",\n        legend.margin = margin(t = 0, b = 0))\n```\n\nBut let's think about what we would have to do to adjust for the confounder $Z$. Ideally, we would like to compare treated and control group in an area where both groups are present. So the lower and upper region should actually be left out. Only where there is overlap of both groups, we can compare apples with apples. Focusing only on this (somewhat arbitrary) data points and drawing the lines and curves for both specifications of the regression, we get another different result. Now it seems, that there is no effect at all.\n\n```{r echo=FALSE}\n# Plot regression line (matched data)\nggplot(all_data, aes(x = education, y = outcome, fill = treatment)) +\n  geom_point(aes(alpha = type), size = 5, pch = 19) +\n  geom_abline(slope = filter(model_better, term == \"education\")$estimate, \n              intercept = filter(model_better, term == \"(Intercept)\")$estimate,\n              color = ggthemr::swatch()[2], size = 0.75) +\n  geom_abline(slope = filter(model_better, term == \"education\")$estimate, \n              intercept = filter(model_better, term == \"(Intercept)\")$estimate +\n                filter(model_better, term == \"treatmentTreated\")$estimate,\n              color = ggthemr::swatch()[3], size = 0.75) +\n  scale_alpha_manual(values = c(1, 0.2), guide = \"none\") +\n  labs(x = \"Education\", y = \"Outcome\") +\n  coord_cartesian(xlim = c(8, 30), ylim = c(0, 15)) +\n  theme(legend.position = \"bottom\",\n        legend.margin = margin(t = 0, b = 0))\n```\n\nSo, how do we know what units to select, especially when there is more than one dimension? We will explore some techniques in the following sections but the short answer is: we need to create a balance for vales of all confounding variables treatment and control group, i.e. treatment and control group should be as similar as possible. And of course, we also need to assume, that all confounding variables are observed.\n\n# Subclassification Estimator\n\nAlthough not often used in practice, the subclassification estimator is an intuitive way of thinking about matching comparable observations and thereby controlling for confounders.\n\nEssentially, the subclassification estimator estimates local treatment effects withing small groups that share the same values for (confounding) covariates. Sometimes, values does not need to be the same but only similar, e.g. for continuous variables like age it is very unlikely to find another observation unit with the exact same birthday, so you would define e.g. a year. By only comparing observations in a small subgroup as defined by the covariates, conditional independence is ensured.\n\nImagine, that a treatment was not randomly assigned for women and men and sex also plays a role for the outcome as well. One imaginary example could be the effect of a trainee program on later salary that was advertised more heavily to women and therefore more women participated. And being a women might also have an impact on salary. Then, we have the situation of a confounding variable, sex, and to control for it, we estimate a treatment effect for women and a treatment effect for men and average the effects weighted by the respective subsample size.\n\nTo check how that affects the estimated treatment effect we can simulate some data according to the variable relationships.\n\n```{r}\nconfounder <- 'dag {\nD [exposure,pos=\"0.000,0.000\"]\nY [outcome,pos=\"2.000,0.000\"]\nZ [pos=\"1.000,1.000\"]\nZ -> D\nZ -> Y\nD -> Y\n}'\nggdag(confounder) + theme_dag()\n```\n\n```{r}\n# number of observations\nn <- 1e+3\n# variables\nZ <- rbernoulli(n, 0.5) # 0 => Male, 1 => Female\nD <- rbernoulli(n, p = if_else(Z, 0.65, 0.35)) # 1 => Treat, 0 => Control\nY <- 0.2*D - 0.1*Z + rnorm(n, 5, 0.1) # => e.g. Salary\ndf <- tibble(\n  Z = Z,\n  D = D,\n  Y = Y\n)\n```\n\n$Z$ is the confounder, $D$ the treatment and $Y$ is the outcome. As you can see both $D$ and $Y$ are related to $Z$ and $Y$ is influenced by both $D$ and \\$Z\\$. But we are only interested in the effect of $D$ on $Z$ and want to isolate it. From the commands, we know that the true causal effect of $D$ on $Y$ is 0.2.\n\nLet's see what a naive comparison would return, where we would just compare average salary of the individuals who have participated in the trainee program are compared to the individuals who have not participated.\n\n```{r}\n# Naive comparison\n#broom::tidy(lm(Y ~ D, df))\nE_0 <- mean(df[df$D==F, ]$Y)\nE_1 <- mean(df[df$D==T, ]$Y)\nE_1 - E_0\n```\n\nDue to confounding, the naive comparison cannot reconstruct our implemented treatment effect and is off. We should get closer if we account for confounding by taking averages treatment effects for men and women separately.\n\n```{r}\n# Subclassification estimator (subclasses: Z = 0 and Z = 1)\n# E(Z, D)\nE_00 <- mean(df[(df$Z==F & df$D==F), ]$Y)\nE_10 <- mean(df[(df$Z==T & df$D==F), ]$Y)\nE_01 <- mean(df[(df$Z==F & df$D==T), ]$Y)\nE_11 <- mean(df[(df$Z==T & df$D==T), ]$Y)\n# Weighted by K\nK <- mean(Z)\nK*(E_11-E_10) + (1-K)*(E_01 - E_00)\n```\n\nAnd in fact, now we are really close to the true treatment effect. The remaining difference is caused by randomness in our sampling process.\n\nThis way, we have closed the backdoor and are able to retrieve the causal effect. However, note that the effect can only be causally interpreted, if sex is the only confounding variable. If there are more confounders, we have to build smaller groups that are defined by value combinations of all confounders, which will at some point lead groups that are extremely small or maybe even empty. This is called the curse of dimensionality and is one reason why the subclassification estimator is rarely used in practice.\n\n# Matching as a Concept\n\nIn general, the outcome of a matching method are weights for each observation based on one or several matching variables, for some matching methods the weights are either 0 or 1 but there are also a lot of methods that give weights between 0 and 1 to observations.\n\nThe matching variables need to cover the variables that can, when adjusted on, block all backdoor paths between our treatment variable and the outcome. Then, the treatment effect is computed as a weighted mean of the outcomes for the treatment and control group.\n\nMatching methods can be classified into two main approaches: matching based on (1) distance and (2) matching based on propensity scores.\n\n1.  Distance: Observations are similar if they have similar covariates (or similar values for the matching variables). This approach minimizes the distance between observations in treatment and control group based on their covariate values.\n\n2.  Propensity: Observations are similar if they are equally likely to be treated, i.e. matching variables are used to compute how likely an observation is to be in treatment group, regardless whether it actually is in the treatment or control group.\n\n```{r echo=FALSE}\ndf <- tibble(\n  x1 = c(1, 2, 3, 3, 3.2),\n  x2 = c(1.5, 2.2, 3.1, 2.7, 2.5),\n  m  = as.factor(c(0, 1, 0, 0, 0)),\n  w  = c()\n)\ntreated <- tibble(\n  x1 = 2.2,\n  x2 = 2.2\n)\np1 <- ggplot(df, aes(x = x1, y = x2)) +\n  geom_point(size = 4) +\n  geom_point(aes(x = treated$x1, treated$x2),\n             pch = 23, size = 4, color = \"white\", fill=\"green\") +\n  coord_cartesian(xlim = c(0, 4),\n                  ylim = c(0, 4)) +\n  theme(legend.position = \"none\")\np2 <- ggplot(df, aes(x = x1, y = x2, color = m)) +\n  geom_point(size = 4) +\n    geom_point(aes(x = treated$x1, treated$x2),\n             pch = 23, size = 4, color = \"white\", fill=\"green\") +\n  coord_cartesian(xlim = c(0, 4),\n                  ylim = c(0, 4)) +\n  theme(legend.position = \"none\")\neuclidean <- function(a, b) sqrt(sum((a - b)^2))\ndistance <- lapply(1:nrow(df), function(row) {\n  vec_df <- c(df$x1[row], df$x2[row])\n  vec_tr <- as_vector(treated)\n  \n  euclidean(vec_df, vec_tr)\n}) %>% unlist()\ndf$w <- 1/distance\np3 <- ggplot(df, aes(x = x1, y = x2, size = w)) +\n  geom_point() +\n    geom_point(aes(x = treated$x1, treated$x2),\n             pch = 23, size = 4, color = \"white\", fill=\"green\") +\n  coord_cartesian(xlim = c(0, 4),\n                  ylim = c(0, 4)) +\n  theme(legend.position = \"none\")\ngridExtra::grid.arrange(p1, p2, p3, ncol=3)\n```\n\nWe can now outline a structure for the general process of matching that applies to all methods.\n\nFirst, it starts with some kind of preprocessing, which is a \"manual\" part, where you use all information about the causal mechanisms that you have. Essentially, it forces you to look at the DAG you can draw based on all your theoretical knowledge and thoughts, and particularly what you know about the treatment assignment. In observational studies, this will leave you with a sample that is different from your raw sample. In randomized studies, it might be the same as you do not have to for example close a backdoor path.\n\nThen, using this preprocessed data you can build your model to estimate the treatment effect.\n\nAs already mentioned, another difference across methods is whether observations are compared to matches, which classify other observations as either in our out or compared to matched weighted samples, where each observation obtains a different weight depending on how close they are. For matches, you have to decide how many to include or what the worst acceptable match is while for matched weighted samples you need to decide how weights decay with distance.\n\nNow, let's look at some methods in detail.\n\n## Single Matching Variable\n\nProbably the most simple method, though rarely applied in practice, is matching on a single variable. Its rare use in practice is due to the fact that matching on a single variable is only applicable if there is only one backdoor path that can be closed by this matching variable.\n\nBut for ease of explanation, we'll have a look at it.\n\n```{r}\nconfounder <- 'dag {\nD [exposure,pos=\"0.000,0.000\"]\nY [outcome,pos=\"2.000,0.000\"]\nZ [pos=\"1.000,1.000\"]\nZ -> D\nZ -> Y\nD -> Y\n}'\nggdag(confounder) + \n  annotate(\"text\", x = 0.5, y = 1, label = \"Z fixed at constant level\") +\n  theme_dag()\n```\n\n!!! EXAMPLE:\n\ncredit card holders, monthly bills, repayment status (pay on time, delay payment) April - September\n\n(D) being late April \\<- size of bill in April -\\> (Y) being late Sept\n\n### (Coarsened) Exact Matching\n\n!!! pick one observation. define distance. single or multiple comparables.\n\nWe are trying to select observations in the control group that are similar to those in the treated group. To do so, we need to define what similar means. Here, we will say that similar observations are observations that share similar values for our matching variable (size of bill in April). By enforcing treatment and control group to have little variation in the matching variable, we close the backdoor. Only when the backdoor variable varies, it can induce changes in treatment and outcome and when we keep it at a certain level, the only effect from treatment to outcome is the direct effect.\n\nHow many? With our without replacement? Tradeoff between bias and variance (more matches, less variance and more bias) (Matching with replacement less bias because better matches and is not order-dependent)\n\n-   one-to-one matching: selecting the best match\n\n-   top $k$ matching: k-nearest-neighbor matching\n\n-   all \"acceptable\" matches: every match by some metric of acceptability (hard to define).\n\n### Matched weighted sample\n\nNow we will move away from a an observation being in or out depending on whether it is a best match to some unit. Instead we use an alternate approach that works by looking at all control observations and checking how close they are to treated observations. An observation is neither in our out but receives a weight depending on its similarity to a treated observation. The closer a control observation is to a treatment observation, the higher its weight.\n\nHow to construct weights?\n\n-   Kernel matching: kernel function takes difference and returns weight. Weight eventually gets to zero. Better matches obtain higher weights than less-good matches, bad matches obtain weight of zero. Different kinds of kernels.\n\n-   Inverse probability weighting: specifically designed for use with propensity scores. Each observation is weighted by the inverse of the probability for its own treatment status. Simply put, atypical observations receive a high weight, so if you were actually treated which was unlikely based on your covariates, you receive a high weight.\n\n!!! PLOT: One-to-one matching (color of controls) vs weight matching (size of controls)\n\nComparison: selecting matches more intuitive and easier to implement but more sensitive. weights to account for quality of matches\n\n## Application: Multiple Matching Variables\n\nLet us imagine, you want to reduce the number of sick days in your company by implementing a health program that employees are free to participate in. By learning about how to improve their health, you expect your employees to call in sick less frequently.\n\nNow you already see that the treatment, participation in the health program, is on a voluntary basis and therefore treatment assignment might be confounded by variables such as age and initial health status. Older and sicker people might be more interested to learn about techniques and procedures to improve their health and also might benefit more from the program. Also, initial health status might be affected by age.\n\nWe can use a DAG to think about the correct identification strategy.\n\n```{r}\n# define DAG\ndag_model <- 'dag {\n  bb=\"0,0,1,1\"\n  \"Health Program\" [exposure,pos=\"0.25,0.2\"]\n  \"Initial Health Status\" [pos=\"0.35,0.25\"]\n  \"Sick Days\" [outcome,pos=\"0.35,0.2\"]\n  Age [pos=\"0.25,0.25\"]\n  \"Initial Health Status\" -> \"Health Program\"\n  \"Initial Health Status\" -> \"Sick Days\"\n  Age -> \"Health Program\"\n  Age -> \"Initial Health Status\"\n  Age -> \"Sick Days\"\n}'\n# Directed Acyclic Graph\nggdag_status(dag_model, text = FALSE, use_labels = \"name\") +\n  guides(color = \"none\") +\n  theme_dag()\n# Directed Acyclic Graph with adjustment sets\nggdag_adjustment_set(dag_model, shadow = T, use_labels = \"name\", text = F) +\n  guides(color = \"none\") +  # Turn off legend\n  theme_dag()\n```\n\nThere are two backdoor paths that we need to close, initial health status and age.\n\n```{r}\nadjustmentSets(dag_model)\n```\n\n```{r include=FALSE}\n# [3] Generate synthetic data ----\n# Number of observations\nn <- 1e+4\n# Z_1: age\nage <- scales::rescale(\n  rbeta(n, shape1 = 3, shape2 = 2), \n  to = c(18, 65))\n# Z_2: initial health status (sick days before)\nsick_days_before <- round(rexp(n, 25/age) + rnorm(n, 2, 0.5))\n# D: participation in health program\nd_cont <- 0.04*age + sick_days_before + rnorm(n)\nhealth_program <- if_else(\n  d_cont > median(d_cont),\n  rbernoulli(n, 0.65),\n  rbernoulli(n, 0.35)\n  )\nmean(health_program)\n        \n# Y: sick days (after)\nsick_days <- round(\n  0.04*age + sick_days_before + 0.5*health_program + rnorm(n, 2, 1)\n  )\n# Add variables to tibble\ndf <- tibble(\n  age              = age,\n  sick_days_before = sick_days_before,\n  health_program   = health_program,\n  sick_days        = sick_days\n)\n```\n\nA naive estimate would be\n\n```{r}\n# Naive estimation (not accounting for backdoors)\nmodel_naive <- lm(sick_days ~ health_program, data = df)\nbroom::tidy(model_naive)\n```\n\nwhich is different from the !!! TRUE TREATMENT EFFECT.\n\n### (Coarsened) Exact Matching\n\nIt is not difficult to extend the approaches defined above to multiple matching variables. Regarding the \"selecting matches\" approach, multiple variables are used for the computations instead of a single. Again, in case of exact matching, only observations that share the same values are matched in.\n\nTo perform Coarsened Exact Matching (CEM) you can use the `MatchIt` package in R. If you do not specify how to coarsen the data, it will be done automatically based on an algorithm.\n\n```{r}\nlibrary(MatchIt)\n# Without specifying coarsening\n# (1) Matching\ncem <- matchit(health_program ~ age + sick_days_before,\n               data = df, \n               method = 'cem', \n               estimand = 'ATE')\n# Covariate balance\nsummary(cem)\n```\n\nWe are already closer to our true treatment effect.\n\n```{r}\ndf_cem <- match.data(cem)\n# (2) Estimation\nmodel_cem <- lm(sick_days ~ health_program, data = df_cem, weights = weights)\nbroom::tidy(model_cem)\n```\n\nWe can also provide values to coarsen the data in order to control for the number of subsamples. Again, we also check the balance.\n\n```{r}\n# Custom coarsening\n# (1) Matching\ncutpoints <- list(age = seq(25, 65, 15), sick_days_before = seq(3, 22, 5))\ncem_coars <- matchit(health_program ~ age + sick_days_before,\n                     data = df, \n                     method = 'cem', \n                     estimand = 'ATE',\n                     cutpoints = cutpoints)\n# Covariate balance\nsummary(cem_coars)\n```\n\nWe can also visualize the subsamples and see how data points are weighted.\n\n```{r}\ndf_cem_coars <- match.data(cem_coars)\n# Plot grid\nggplot(df_cem_coars, aes(x = age, y = sick_days_before,\n                         size = weights, color = as.factor(health_program))) +\n  geom_point(alpha = .2) +\n  geom_abline(data.frame(y = cutpoints$sick_days_before),\n              mapping = aes(intercept = y, slope = 0)) +\n  geom_vline(data.frame(y = cutpoints$age),\n              mapping = aes(xintercept = y)) +\n  theme(legend.position = \"none\")\n```\n\nNow, with fewer subsamples, the estimate is worse. It seems, the backdoors are not properly closed.\n\n```{r}\n# (2) Estimation\nmodel_cem_coars <- lm(sick_days ~ health_program, data = df_cem_coars, \n                      weights = weights)\nbroom::tidy(model_cem_coars)\n```\n\n### Nearest-Neighbor matching\n\nFor nearest neighbor matching, the difference between two observations based on multiple variables is computed and reduced to a scalar. One of the most popular techniques used to find so called \"nearest neighbors\" is the euclidean distance.\n\nWe just have to change a few arguments and decide to use the Mahalanobis distance. Then, we check how similar treatment and control group are after matching.\n\n```{r}\n# (1) Matching\n# replace: one-to-one or one-to-many matching\nnn <- matchit(health_program ~ age + sick_days_before,\n              data = df,\n              method = \"nearest\",\n              distance = \"mahalanobis\",\n              replace = T)\n# Covariate Balance\nsummary(nn)\n```\n\nThis method also brings us closer to the true treatment effect.\n\n```{r}\ndf_nn <- match.data(nn)\n# (2) Estimation\nmodel_nn <- lm(sick_days ~ health_program, data = df_nn, weights = weights)\nbroom::tidy(model_nn)\n```\n\n### Curse of dimensionality\n\nWith exact matching and nearest-neighbor matching you quickly run into the curse of dimensionality as your number of covariates grows. If you want to find matches based on very few dimensions, you are way more likely to find them as opposed to matches on a high number of dimensions, where it is very likely that you actually don't find any matches at all.\n\nRegarding exact matching, consider for example the situation with two covariates with each five different values. Then any observations will fall into one of 25 different cells that are given by the covariate value grid. And now imagine ten covariates with three different values: it already creates \\~60k cells, which increases the likelihood of a cell being populated by only one or zero observations substantially. Then, estimation of treatment effects is not possible for many of the observations.\n\nNearest-neighbor matching is similarly affected by the curse of dimensionality. The more covariates you include, the less likely you are to find a good match. A quick solution, leaving out some covariates, can only be done if you are sure to not throw out any confounders.\n\n### Inverse Probability weighting\n\nOne way to deal with the curse of dimensionality is to use inverse probability weighting (IPW). We already mentioned it above, but let's go into more detail.\n\nWe start by understanding what \"probability\" in inverse probability means. It is the predicted probability of treatment assignment based on the matching variables. So staying in the health program example, we use age and initial health status to predict how likely an employee is to participate in the health program. What we expect is that older and initially more sick people are more likely to participate opposed to younger and healthy people. To model this relationship, we could use for example logistic regression, a regression that predicts an outcome between zero and one. But you are also free to use any classification model that is out there, as here we are not only interested in explaining effects but only in obtaining the probability of treatment, also known as \"propensity score\".\n\nHere, we will use a logistic regression:\n\n```{r}\n# (1) Propensity scores\nmodel_prop <- glm(health_program ~ age + sick_days_before,\n                  data = df,\n                  family = binomial(link = \"logit\"))\nbroom::tidy(model_prop)\n```\n\n```{r}\n# Add propensities to table\ndf_aug <- broom::augment_columns(\n  model_prop, \n  df,\n  type.predict = \"response\") %>% \n  rename(propensity = .fitted)\n```\n\n```{r}\n# Plot histogram of estimated propensities\nggplot(df_aug, aes(x = propensity)) +\n  geom_histogram(alpha = .8, color = \"white\")\n```\n\nHaving obtained the propensity score, you could again measure distances like described above and select matches. In fact, that is widely used matching method, known as propensity score matching. However, there are several reasons why this is not a good identification strategy[^1], mainly, because same propensity score does not imply that observations have the same covariate values and this could actually increase the imbalance. Note, however, that same covariate values indeed imply the same propensity score.\n\n[^1]: <https://gking.harvard.edu/publications/why-propensity-scores-should-not-be-used-formatching>\n\nInstead inverse probability has proven to be a more precise method, particularly when the sample is large enough. So what do we do with the probability/propensity scores in IPW? We use propensity score of an observation unit to in- or decrease its weights and thereby make some observations more important than others. The weight obtains as\n\n$$\nw_i = \\frac{D_i}{\\pi_i} + \\frac{(1-D_i)}{(1-\\pi_i)}\n$$\n\nwhere only one of the terms is always active as $D_i$ is either one or zero. Now we should better understand what \"inverse probability weighting\" actually means. It weights each observation by its inverse of its treatment probability.\n\n```{r}\ndf_ipw <- df_aug %>% mutate(\n  ipw = (health_program/propensity) + ((1-health_program) / (1-propensity)))\ndf_ipw %>% \n  select(health_program, age, sick_days_before, propensity, ipw)\n```\n\nImagine a case of an old employee with a very bad initial health status who chose to participate in the health program, i.e. $D_i=1$. Based on his/her covariates, it was very likely that he choose to participate and consequently, his propensity score will be rather high, let's assume it was 0.8, for demonstration. Then his/her weight would equal $w_i = \\frac{1}{0.8} = 1.25$.\n\nCompared to that, what weight would a young and healthy person that choose to participate in the program obtain? Let's say his/her probability of participating would be 0.2. Then, his/her weight would be $w_i = \\frac{1}{0.2} = 5$. So we see, he/she would obtain a significantly higher weight.\n\nIn general, IPW weights atypical observations, like a young and healthy person deciding to participate, higher than typical observations. The same applies for both treatment and control group. If you want, you can check it out yourself.\n\n```{r}\n# (2) Estimation\nmodel_ipw <- lm(sick_days ~ health_program,\n                data = df_ipw, \n                weights = ipw)\nbroom::tidy(model_ipw)\n```\n\nSome propensity values are very extreme and therefore obtain an extreme weight. We should probably filter them out to improve our estimate.\n\n```{r}\ndf_ipw %>% \n  select(health_program, age, sick_days_before, propensity, ipw) %>% \n  arrange(desc(ipw))\nmodel_ipw_trim <- lm(sick_days ~ health_program,\n                data = df_ipw %>% filter(propensity %>% between(0.15, 0.85)),\n                weights = ipw)\nbroom::tidy(model_ipw_trim)\n```\n\nOpposed to other methods, IPW, which is specifically designed for use with propensity scores, allows us to use all data in terms of number of observations and dimensions and the only decision we need to take is how to estimate the propensity score. It is important to note that the model does not need to predict as accurate as possible but it is more crucial that it accounts for all confounders.\n\n### Comparison\n\nYou see, that there many ways backdoors can be closed.\n\n```{r}\nmodelsummary::modelsummary(list(\"Naive\" = model_naive,\n                                #\"All\"   = model_adj,\n                                \"CEM1\"  = model_cem,\n                                \"CEM2\"  = model_cem_coars,\n                                \"NN\"    = model_nn,\n                                \"IPW1\"  = model_ipw,\n                                \"IPW2\"  = model_ipw_trim))\n```\n\n# Assumptions\n\nTo obtain valid estimates with any matching estimator, we still need to fulfill some assumptions. Most important are the following:\n\n-   Conditional Independence: all backdoors needs to be closed so it has to be ensured that all confounders are in the set of matching variables.\n\n-   Common Support: for treated units, there need to exist appropriate control units. Without a substantial overlap in the distribution of matching variables or the propensity score, estimating causal effects is impossible.\n\nParts of these assumptions can be checked by looking at the balance of covariates. Useful metrics include summary statistics including means, standard deviations, difference-of-means test etc.\n\n!!! Show raw balance and matched balance (Matching::MatchBalance or vtable::sujmtable)\n\nIf the degree balance is not satisfactory, you can change parameters of your matching method and do a new iteration until you are confident to have a good balance between treatment and control.\n\nHaving fulfilled the necessary assumptions allows the valid estimation of a treatment. It is interesting to note that, depending on what method you chose, a different kind of treatment effect is estimated. Most of the methods start with having a treated unit and search for matches (selecting or weighting) across the control units, which will return the average treatment effect on the treated, $ATT$. By the same logic, these methods can also yield the average treatment effect on the untreated, $ATU$.\n\nThen, the average treatment effect can be estimated by\n\n$$\nATE = p*ATT + (1-p)*ATU\n$$\n\nIn case of IPW, $ATE$ is computed directly, as it changes the weights of units from both groups.\n\n# Conclusion\n\nMatching methods are a very active research field and even thinking about the correct way to choose parameters in those methods offers a wide range of questions that there is no definite answer to. To some degree, choosing matching parameters is arbitrary. A benefit, however, is that after matching model dependence is reduced when using simple techniques like weighted means.\n\nBut how does it compare to using a simple linear regression? In one of the previous chapters, we said that closing back doors can also be achieved by including confounders into the regression equation. One difference is that when using regression, the $ATE$ points in direction where covariates have more variance, i.e. when there is a higher treatment variance for older people for example, they obtain a higher weight as compared to the matching approach. Another difference is that a regression hinges on the assumption of linearity, which we do not need to assume in matching approaches.\n\n# Assignment\n\nImagine, the following situation. You are running an online store and you one year ago, you introduced a plus membership to bind customers to your store and increase revenue. The plus memberships comes at a small cost for the customers, which is why not all of the customers subscribed.\n\nLoad the data, look at the variables and draw a DAG that you think shows the situation best. Then, compute\n\n-   a naive estimate\n\n-   an estimate using coarsened exact matching (custom or default)\n\n-   an estimate using nearest-neighbor matching\n\n-   an estimate using inverse probability weighting\n\nand compare the results. Argue what estimates can be causally interpreted.\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"paged","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":{"blogdown::html_page":{"toc":true}},"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"output-file":"06_match.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.269","editor":"visual","theme":["darkly","../../theme-darkly.scss"],"mainfont":"arial","linestretch":1.7,"title":"Matching and Subclassification","linktitle":"Matching and Subclassification","date":"2022-10-01","menu":{"example":{"parent":"Toolbox","weight":7}},"type":"docs","editor_options":{"chunk_output_type":"console"}},"extensions":{"book":{"multiFile":true}}}}}