{
  "hash": "715dcbbb8669aafc344662799677a6d9",
  "result": {
    "markdown": "---\ntitle: \"Difference-in-Differences\"\nlinktitle: \"Difference-in-Differences\"\ndate: \"2022-10-01\"\noutput:\n  blogdown::html_page:\n    toc: true\nmenu:\n  example:\n    parent: Toolbox\n    weight: 9\ntype: docs\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n\n# Introduction\n\nThe most popular research design in quantitative and social sciences is the **difference-in-differences (DiD)** approach. As it name suggests, the method **captures differences by observing a treatment and a control group over time** to estimate causal average effects.\n\nDiD provides a nonexperimental technique that, in its simplest form, compares two groups (control and treatment) at two points in time (before treatment and after) by observing if and how different both group's outcome evolve.\n\nBy taking two differences, two different kind of biases should be avoided. First, by comparing both groups at both points in time, any external effect that affects the outcome through time should play no role as it affects both groups. Secondly, taking only the difference of change in consideration, selection bias is eliminated and potential outcomes can vary.\n\nAs can be seen in the table, the difference in outcome for the treatment group before and after treatment is $D + T$, while for the control group it is only $T$. The difference of these two differences then reduces to only $D$, which is the treatment effect we want to estimate.\n\n| Group           | Time | Outcome                   | 1st Difference | DiD |\n|-----------------|------|---------------------------|----------------|-----|\n| Treatment (D=1) | 0    | $Y= Y_{T=0, D=1}$         |                |     |\n|                 | 1    | $Y = Y_{T=0,D=1} + T + D$ | $T +D$         |     |\n|                 |      |                           |                | $D$ |\n| Control (D=0)   | 0    | $Y = Y_{T=0, D=0}$        |                |     |\n|                 | 1    | $Y = Y_{T=0, D=0} + T$    | $T$            |     |\n\nWe can also break it down in our known notation:\n\n$$\nATE = \\bigg(E[Y_{D=1}|T=1] - E[Y_{D=1}|T=0] \\bigg)- \\bigg(E[Y_{D=0}|T=1] - E[Y_{D=0}|T=0]\\bigg)\n$$\n\nBecause there are a lot of subscripts, it can also help to write down the formula in pseudo-math:\n\n$$\nATE = (Y_{Treatment, After} - Y_{Treatment, before}) - (Y_{Control, After} - Y_{Control, Before})\n$$\n\nOpposed to methods where we just know one outcome - the \"after\" outcome, regardless of whether a unit received or did not receive treatment - we do not have to assume that the potential otucomes $E[Y_0|D=1] = E[Y_0|D=1]$ are equal. That is a big difference, because do not have to assume that observation units are similar in all their characteristics.\n\nInstead DiD hinges on a different assumption, the **parallel trends assumption.** It says that, in absence of treatment for both groups, they would be expected to evolve similarly over time. In other words, we do not expect the potential outcome to be similar, but the change of outcomes from before to after. It implies that there is no other factor that has only an impact on just one of the groups. If units differ in characteristics, they are only allowed to have a constant effect. If the effect varies with time, the paralell trends assumption is violated.\n\n# Application\n\nTo understand DiD and the parallel trends assumption becomes easier when using plots. Therefore, we will now use an application to go through all steps from stating assumptions to estimation. We create two scenarios:\n\n-   **Scenario A**: parallel trends assumption fulfilled\n\n-   **Scenario B**: parallel trends assumption violated\n\nLet's imagine, you are manager of a company that has two stores, one of them being in City 1 and the other being in City 2. You want to test the effectiveness of a local ad campaign on sales. Therefore, you will run a campaign at the store in City 1 but not in City 2 and keep track of sales in the periods before and after the treatment.\n\nWe generate a data set for two scenarios according to the following relationships:\n\nScenario A:\n\n$Y = D + P + X + U_y$\n\nScenario B:\n\n$X = S + U_x$\n\n$Y = D + P + X + XP + U_y$\n\n$Y$ - sales\n\n$D$ true treatment effect\n\n$P$ is periods\n\n$S$ store index\n\n$X$ covariate, e.g. ecosystem\n\n$U_y, U_x$ error terms\n\nWith the function *generate_data()* we generate data with arbitrary values for the number of stores, number of observed periods, the size of the true treatment effect, the timing of treatment and level of noise in the data generating process. Data is generated for both scenarios as can be seen at the suffixes.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching packages ───────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse 1.3.0 ──\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n✔ ggplot2 3.3.5     ✔ purrr   0.3.4\n✔ tibble  3.1.6     ✔ dplyr   1.0.8\n✔ tidyr   1.2.0     ✔ stringr 1.4.0\n✔ readr   2.1.2     ✔ forcats 0.5.1\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n── Conflicts ──────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n```\n:::\n\n```{.r .cell-code}\ngenerate_data <- function(\n  S = 2, # number of groups\n  P = 10, # number of periods\n  D_size = 1, # effect of treatment\n  D_time = NULL, # time of treatment\n  y_0 = 50, # base value for y\n  sd = 1 # standard deviations for randomly generated sequences\n){\n  # create group period dyads\n  s <- rep(0:1, each = P)\n  p <- rep(1:P, S)\n  \n  # timing and size of treatment (effect)\n  D     <- D_size\n  if (missing(D_time)) D_time <- P/2\n  after <- as.numeric(ifelse(p, p > D_time))\n  \n  # create relation between independent variables and treatment (actually\n  # other way round, but easier to simulate this way)\n  x1 <- rnorm(S*P, s, sd)\n  \n  # create dependent variable ...\n  # ... for scenario (a)\n  y_a <- y_0 + D*s*after + 1/5*p + x1 + rnorm(S*P, 0, sd)\n  \n  # ... for scenario (b)\n  y_b <- y_0 + D*s*after + 1/5*p + x1 + s*x1 + 1/3*p*x1 + rnorm(S*P, 0, sd)\n  \n  # add variables to table\n  df <- tibble(\n    store   = s,\n    period  = p,\n    after   = after,\n    x1      = x1,\n    sales_a = y_a,\n    sales_b = y_b\n  )\n  \n  # return table\n  return(df)\n}\n```\n:::\n\n\nWe choose to generate a data set with a true treatment effect of 1 and 10 observed periods. For now, we just have one store as a treated unit and one store as a non-treated unit. Later, we will extend it to a larger number of stores per group, but for demonstration purpose, we restrict it to two stores, initially. We have 10 periods with 5 periods before and 5 after treatment. Lastly, we add a little bit of noise.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Generate one sample\nP <- 10 # number of periods\nD <- 1  # true treatment effect\ndf <- generate_data(P = P, D_size = D, sd = 0.01)\n```\n:::\n\n\n## Parallel trends\n\n### Scenario A\n\nTo compute an estimated treatment effect, we filter the data to the two periods just around treatment and implement the formulas as in the introduction. Not surprisingly, we get an estimate that is very close to our true treatment effect.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# [1.1.1] (a) Fulfillment ----\n# Scenario (a)\n# Only show last data point before and first data point after treatment.\ndf_zoom_in_a <- df %>% \n  filter(period %in% (P/2):(P/2+1)) %>%\n  mutate(store_discrete = as.factor(store)) %>% \n  rename(sales = sales_a)\n\n# Manually compute differences\n# Difference between treatment and control group BEFORE treatment\nbefore_control_a <- df_zoom_in_a %>%\n  filter(store == 0, after == 0) %>% \n  pull(sales)\nbefore_treatment_a <- df_zoom_in_a %>%\n  filter(store == 1, after == 0) %>% \n  pull(sales)\n\ndiff_before_a <- before_treatment_a - before_control_a\n\n# Difference between treatment and control group AFTER treatment\nafter_control_a <- df_zoom_in_a %>%\n  filter(store == 0, after == 1) %>% \n  pull(sales)\nafter_treatment_a <- df_zoom_in_a %>%\n  filter(store == 1, after == 1) %>% \n  pull(sales)\n\ndiff_after_a <- after_treatment_a - after_control_a\n\n# Difference-in-differences. Unbiased estimate if parallel trends is correctly\n# assumed and there is no hidden confounding. Estimate may vary from true\n# treatment effect, as we also include some noise in the data generating \n# process.\ndiff_diff_a <- diff_after_a - diff_before_a\nsprintf(\"Estimate: %.2f, True Effect: %.2f\", diff_diff_a, D)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Estimate: 1.05, True Effect: 1.00\"\n```\n:::\n:::\n\n\nLooking at the last period before and the first period after treatment, the impact of treatment can clearly be seen. The dashed line represents the counterfactual value for the treated group, i.e. the value it would have if it had not been treated. This value is not observed, but by the paralell trends assumptions, it would have developed like the value for the untreated group.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Plot\nggplot(df_zoom_in_a, aes(x = period, y = sales, color = store_discrete)) +\n  geom_line(size = .95) +\n  scale_x_continuous(name =\"\", \n                   breaks=c(5, 5.5, 6),\n                   labels = c(\"Before Treatment\", \n                              \"Treatment\",\n                              \"After Treatment\")) +\n  scale_y_continuous(name = \"Sales\", labels = scales::number_format(accuracy = 0.1)) +\n  scale_color_discrete(labels = c(\"Control Group\", \"Treatment Group\")) +\n  guides(colour = guide_legend(reverse = T)) +\n  geom_vline(xintercept = P/2 + .5, color = ggthemr::swatch()[4]) + \n  annotate(geom = \"segment\", x = (P/2), xend = (P/2+1),\n           y = before_treatment_a, yend = after_treatment_a - diff_diff_a,\n           linetype = \"dashed\", color = ggthemr::swatch()[2], size = .95) +\n  annotate(geom = \"segment\", x = (P/2+1), xend = (P/2+1),\n           y = after_treatment_a, yend = after_treatment_a - diff_diff_a,\n           linetype = \"dashed\", color = \"black\") +\n  annotate(geom = \"label\", x = (P/2+.98), y = after_treatment_a - (diff_diff_a / 2), \n           label = \"Treatment effect\", size = 3) +\n  annotate(geom = \"text\", x = (P/2) + 0.6, y = before_control_a + 1.1*diff_before_a + .1, \n            label = \"Counterfactual\", size = 4, \n           #angle = atan(after_control_a - before_control_a) * 180/pi\n           angle = 3) +\n  theme(panel.grid.minor.x = element_blank(),\n        legend.title = element_blank(), legend.position = \"bottom\") +\n  ggtitle(\"Parallel Trends Assumption\")\n```\n\n::: {.cell-output-display}\n![](07_did_files/figure-html/unnamed-chunk-8-1.png){fig-align='center' width=75%}\n:::\n:::\n\n\n### Scenario B\n\nRepeating the steps for scenario B yields an unexpected result. The estimated treatment effect is different from what we would have expected.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# [1.1.2] (b) Violation ----\n# Scenario (b)\n# Only show last data point before and first data point after treatment.\ndf_zoom_in_b <- df %>% \n  filter(period %in% (P/2):(P/2+1)) %>%\n  mutate(store_discrete = as.factor(store)) %>% \n  rename(sales = sales_b)\n\n# Manually compute differences\n# Difference between treatment and control group BEFORE treatment\nbefore_control_b <- df_zoom_in_b %>%\n  filter(store == 0, after == 0) %>% \n  pull(sales)\nbefore_treatment_b <- df_zoom_in_b %>%\n  filter(store == 1, after == 0) %>% \n  pull(sales)\ndiff_before_b <- before_treatment_b - before_control_b\n\n# Difference between treatment and control group AFTER treatment\nafter_control_b <- df_zoom_in_b %>%\n  filter(store == 0, after == 1) %>% \n  pull(sales)\nafter_treatment_b <- df_zoom_in_b %>%\n  filter(store == 1, after == 1) %>% \n  pull(sales)\ndiff_after_b <- after_treatment_b - after_control_b\n\n# Difference-in-differences. Unbiased estimate if parallel trends is correctly\n# assumed and there is no hidden confounding. Estimate varies from true\n# treatment effect due to confounding and added noise.\ndiff_diff_b <- diff_after_b - diff_before_b\nsprintf(\"Estimate: %.2f, True Effect: %.2f\", diff_diff_b, D)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Estimate: 1.45, True Effect: 1.00\"\n```\n:::\n:::\n\n\nAgain, the picture is very similar. Having only four data points, treatment before and after and control before and after, there is no way to test the paralell trends assumption which leaves room for doubt. So how can we check whether we made a mistake or the paralell trends assumption is violated?\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Plot\nggplot(df_zoom_in_b, aes(x = period, y = sales, color = store_discrete)) +\n  geom_line(size = .95) +\n  scale_x_continuous(name =\"\", \n                     breaks=c(5, 5.5, 6),\n                     labels = c(\"Before Treatment\", \n                                \"Treatment\",\n                                \"After Treatment\")) +\n  scale_y_continuous(name = \"Sales\") +\n  scale_color_discrete(labels = c(\"Control Group\", \"Treatment Group\")) +\n  guides(colour = guide_legend(reverse = T)) +\n  geom_vline(xintercept = P/2 + .5, color = ggthemr::swatch()[4]) + \n  annotate(geom = \"segment\", x = (P/2), xend = (P/2+1),\n           y = before_treatment_b, yend = after_treatment_b - diff_diff_b,\n           linetype = \"dashed\", color = \"#00bfc4\", size = .95) +\n  annotate(geom = \"segment\", x = (P/2+1), xend = (P/2+1),\n           y = after_treatment_b, yend = after_treatment_b - diff_diff_b,\n           linetype = \"dashed\", color = \"black\") +\n  annotate(geom = \"label\", x = (P/2+.98), y = after_treatment_b - (diff_diff_b / 2), \n           label = \"Treatment effect\", size = 3) +\n  annotate(geom = \"text\", x = (P/2) + 0.6, y = before_control_b + 1.1*diff_before_b, \n           label = \"Counterfactual\", size = 4, \n           #angle = atan(after_control_b - before_control_b) * 180/pi\n           angle = 3) +\n  theme(panel.grid.minor.x = element_blank(),\n        legend.title = element_blank(), legend.position = \"bottom\") +\n  ggtitle(\"Parallel Trends Assumption\")\n```\n\n::: {.cell-output-display}\n![](07_did_files/figure-html/unnamed-chunk-12-1.png){fig-align='center' width=75%}\n:::\n:::\n\n\n## Event Study\n\n### Scenario A\n\nMany researchers therefore try to increase the validity of their results by providing an event study. Not surprisingly (as we created the data ourselves), both groups develop same before the treatment. It cannot rule out all unobserved behavior but an event study lends credibility to the causal interpretation of treatment effects.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# [1.2.1] (a) Fulfillment ----\n# Zoom out and show that parallel trend assumption is fulfilled in scenario (a)\ndf_zoom_out_a <- df %>% \n  mutate(store_discrete = as.factor(store)) %>% \n  filter(period <= (P/2 + 1)) %>% \n  rename(sales = sales_a)\n\ndiff_control <- after_control_a - before_control_a\n\nggplot(df_zoom_out_a, aes(x = period, y = sales, color = store_discrete)) +\n  geom_line(size = .95) +\n  scale_x_continuous(name   = \"Period\", breaks = 1:(P/2+1)) +\n  scale_y_continuous(name = \"Sales\") +\n  scale_color_discrete(labels = c(\"Control Group\", \"Treatment Group\")) +\n  guides(colour = guide_legend(reverse = T)) +\n  geom_vline(xintercept = P/2 + .5, color = ggthemr::swatch()[4]) + \n  annotate(geom = \"segment\", x = (P/2),\n           xend = (P/2 + 1),\n           y = before_treatment_a,\n           yend = before_treatment_a + 1*(diff_control),\n           linetype = \"dashed\", color = \"#00bfc4\", size = .95) +\n  annotate(geom = \"segment\", x = (P/2+1), xend = (P/2+1),\n           y = after_treatment_a, yend = after_treatment_a - diff_diff_a,\n           linetype = \"dashed\", color = \"black\") +\n  annotate(geom = \"label\", x = (P/2+.78), y = after_treatment_a - (diff_diff_a / 2), \n           label = \"Treatment effect\", size = 3) +\n  annotate(geom = \"text\", x = (P/2) + .5, y = before_control_a + 1.1*diff_before_a - .1, \n           label = \"Counterfactual\", size = 4, \n           angle = atan(after_control_a - before_control_a) * 180/pi) +\n  theme(panel.grid.minor.x = element_blank(),\n        legend.title = element_blank(), legend.position = \"bottom\") +\n  ggtitle(\"Parallel Trends Assumption\")\n```\n\n::: {.cell-output-display}\n![](07_did_files/figure-html/unnamed-chunk-14-1.png){fig-align='center' width=75%}\n:::\n:::\n\n\n### Scenario B\n\nPerforming the same steps for scenario B, you see the usefulness of an event study. Other than in scenario A, the paralell trends assumption does not seem to hold. It can be seen from the plot, that the estimated treatment effect is larger than the actual treatment effect. This is due to different trends in both groups. The treatment group has a more positive trend even without treatment and the groups would have further diverged after treatment (see green line). Some of the increase in sales after treatment is therefore attributable to this trends but not the treatment effect.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# [1.2.2] (b) Violation----\n# Zoom out and show that parallel trend assumption is violated in scenario (b)\ndf_zoom_out_b <- df %>% \n  mutate(store_discrete = as.factor(store)) %>% \n  #filter(period <= (P/2 + 1)) %>% \n  rename(sales = sales_b)\n\ntreatment_period_1 <- df_zoom_out_b %>% \n  filter(store == 1, period == 1) %>% \n  pull(sales)\ntreatment_period_5 <- df_zoom_out_b %>% \n  filter(store == 1, period == P/2) %>%\n  pull(sales)\n\ndiff_treatment <- (treatment_period_5 - treatment_period_1) / (P/2)\n\nggplot(df_zoom_out_b, aes(x = period, y = sales, color = store_discrete)) +\n  geom_line(size = .95) +\n  scale_x_continuous(name   = \"Period\", breaks = 1:P) +\n  scale_y_continuous(name = \"Sales\") +\n  scale_color_discrete(labels = c(\"Control Group\", \"Treatment Group\")) +\n  guides(colour = guide_legend(reverse = T)) +\n  geom_vline(xintercept = P/2 + .5, color = ggthemr::swatch()[4]) + \n  annotate(geom = \"segment\", x = (P/2),\n           xend = P,\n           y = before_treatment_b,\n           yend = before_treatment_b + (P/2)*(after_control_b - before_control_b),\n           linetype = \"dashed\", color = \"#00bfc4\", size = .95) +\n  annotate(geom = \"segment\", x = (P/2),\n           xend = P,\n           y = before_treatment_b,\n           yend = before_treatment_b + (P/2)*(diff_treatment),\n           linetype = \"dashed\", color = \"green\", size = .95) +\n  annotate(geom = \"segment\", x = (P/2), xend = (P/2+1),\n           y = before_treatment_b, yend = after_treatment_b - diff_diff_b,\n           linetype = \"dashed\", color = \"#00bfc4\", size = .95) +\n  annotate(geom = \"segment\", x = (P/2+1), xend = (P/2+1),\n           y = after_treatment_b, yend = after_treatment_b - diff_diff_b,\n           linetype = \"dashed\", color = \"black\") +\n  annotate(geom = \"label\", x = (P/2+.98), y = after_treatment_b - (diff_diff_b / 2),\n           label = \"Estimated Treatment effect\", size = 3) +\n  annotate(geom = \"text\", x = (P/2) + 3, y = before_control_b + 1*diff_before_b,\n           label = \"Counterfactual\", size = 4,\n           #angle = atan(after_control_b - before_control_b) * 180/pi\n           angle = 3) +\n  theme(panel.grid.minor.x = element_blank(),\n        legend.title = element_blank(), legend.position = \"bottom\") +\n  ggtitle(\"Parallel Trends Assumption\")\n```\n\n::: {.cell-output-display}\n![](07_did_files/figure-html/unnamed-chunk-16-1.png){fig-align='center' width=75%}\n:::\n:::\n\n\n## Modeling\n\nA more typical situation is usually that there is more than one unit in the treatment and control group. You could e.g. imagine that you are managing more than two stores and are implementing an ad campaign in a specific region.\n\nTo simulate such a scenario, we generate data for 3'000 stores that are split evenly into two regions. In one region, the ad campaign will be run (treatment region) and in the other there will be no campaign (control region). The variable relationships as defined in the previous section still hold.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# [1.4] Linear regression ----\n# Now assume that there are more than two stores and treatment is performed\n# e.g. in a specific region which are, depending on scenario (a) and (b) \n# different.\n# Generate a bunch of samples and combine in one table. Here, we choose a higher\n# standard deviation.\nn_stores <- 3e+3\ndf_lm    <- lapply(1:n_stores, function(R) generate_data(sd = 1)) %>% bind_rows()\ndf_lm    <- df_lm %>% filter(period %in% (P/2):(P/2+1))\n```\n:::\n\n\n### Scenario A\n\nSo how do we compute the average treatment effect? Previously in this chapter, we just used basic math calculations (particularly subtraction). But there is an easier way: we can use regression again. This is because the average treatment effect is the coefficient of the interaction of group and time.\n\n$$\ny_i = \\beta_0 + \\beta_1 * Period_i + \\beta_2 * Treatment_i + \\beta_3 * (Time_i * Treatment_i) + \\epsilon_i\n$$\n\n$Time$ indicates whether the period is before or after the treatment and $Treatment$ whether an observation was treated or not. Then, the coefficient we are interested in is $\\beta_3$, because its term is only active for the treated group after treatment.\n\n!!! x1: maybe purchase power in region\n\nFor scenario A, we can see that there is no need to adjust for the covariate $x1$. If you check the formulas again, your will notice that $x1$ has a constant and time-invariant effect on sales and therefore it does not violate the paralell trends assumption.\n\nIncluding or leaving out $x1$ in the regression yields the a similar unbiased estimate (close to defined true size) for our variable of interest $store:after$, the parameter of interest.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# [1.4.1] (a) ----\n# (a): Due to the construction of the data set, we expect interaction\n# coefficient to be significant as well as the covariate and period. However, as\n# the covariate does not have a time-varying effect, it is not a confounder and\n# interaction coefficient should be unbiased even if not adjusting for the\n# covariate.\nsummary(lm(sales_a ~ store * after , data = df_lm))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = sales_a ~ store * after, data = df_lm)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-5.177 -0.952  0.003  0.956  6.392 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  50.9620     0.0257 1981.04  < 2e-16 ***\nstore         1.0367     0.0364   28.50  < 2e-16 ***\nafter         0.2637     0.0364    7.25  4.5e-13 ***\nstore:after   0.9816     0.0514   19.08  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.4 on 11996 degrees of freedom\nMultiple R-squared:  0.284,\tAdjusted R-squared:  0.283 \nF-statistic: 1.58e+03 on 3 and 11996 DF,  p-value: <2e-16\n```\n:::\n\n```{.r .cell-code}\nsummary(lm(sales_a ~ store * after + x1, data = df_lm))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = sales_a ~ store * after + x1, data = df_lm)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-3.947 -0.680  0.001  0.673  4.205 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 50.98165    0.01821 2799.89   <2e-16 ***\nstore        0.03882    0.02732    1.42     0.16    \nafter        0.22829    0.02575    8.86   <2e-16 ***\nx1           0.98742    0.00903  109.32   <2e-16 ***\nstore:after  0.97851    0.03642   26.87   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1 on 11995 degrees of freedom\nMultiple R-squared:  0.641,\tAdjusted R-squared:  0.641 \nF-statistic: 5.36e+03 on 4 and 11995 DF,  p-value: <2e-16\n```\n:::\n:::\n\n\n### Scenario B\n\nIn scenario B, the effect of *x1* is different because it has a time-varying effect. Therefore it violates the parallel trends assumption, leading to a biased estimate if *x1* is not included (e.g. because it is unobserved).\n\nBecause we constructed the data set ourselves, we are able to see that the bias in fact is quite large and the treatment effect seems to include the actual treatment effect plus the effect of *x1*. Even with including $x1$ and as a main effect and moderator, we cannot fully reconstruct the true treatment effect.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# [1.4.2] (b) ----\n# (b): Due to the construction of the data set, we expect interaction coefficient\n# to be significant and accurate only when adjusting for the time-varying effect\n# of the covariate and main effects for period and covariate.\nsummary(lm(sales_b ~ store*after, data = df))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = sales_b ~ store * after, data = df)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-1.059 -0.419  0.011  0.383  1.050 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   50.591      0.282  179.15  < 2e-16 ***\nstore          2.985      0.399    7.47  1.3e-06 ***\nafter          1.006      0.399    2.52  0.02275 *  \nstore:after    2.683      0.565    4.75  0.00022 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.63 on 16 degrees of freedom\nMultiple R-squared:  0.953,\tAdjusted R-squared:  0.945 \nF-statistic:  109 on 3 and 16 DF,  p-value: 7.44e-11\n```\n:::\n\n```{.r .cell-code}\nsummary(lm(sales_b ~ store*after + after*x1 + store*x1, data = df_lm))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = sales_b ~ store * after + after * x1 + store * x1, \n    data = df_lm)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-4.227 -0.684  0.003  0.683  3.646 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 50.99628    0.01833 2782.65  < 2e-16 ***\nstore       -0.00499    0.03024   -0.16     0.87    \nafter        0.19101    0.02592    7.37  1.8e-13 ***\nx1           2.63604    0.01576  167.23  < 2e-16 ***\nstore:after  0.99312    0.04103   24.21  < 2e-16 ***\nafter:x1     0.35500    0.01819   19.52  < 2e-16 ***\nstore:x1     1.03268    0.01819   56.77  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1 on 11993 degrees of freedom\nMultiple R-squared:  0.943,\tAdjusted R-squared:  0.943 \nF-statistic: 3.31e+04 on 6 and 11993 DF,  p-value: <2e-16\n```\n:::\n:::\n\n\n# Conclusion\n\nDiD is a useful nonexperimental method that relies on the parallel trends assumption which is untestable. We can't prove it but try to justify it by for example showing prior trends. If both groups were evolving similarly before the treatment, that supports the plausibility and appropriateness of using DiD.\n\nAdditionally, there are many extensions to the simple DiD approach we have discussed here like the synthetic control method, that is able to deal with one treated and multiple untreated groups. By matching and weighting the untreated groups, a synthetic group is composed, that is similar in the leadup to the treatment period.\n\n# Assignment\n\nImagine, you are manager of a large health provider that manages many hospitals and you want to test how a new admission procedure affects patient satisfaction.\n\nYou randomly selected 18 hospitals that introduced the new method and compare them to 28 other hospitals that did not introduce the method. For both groups of hospitals you collected data from before and after the introduction. The data you have collected is from patient surveys where they were asked how satisfied they are.\n\nApply the DiD methodology to this application and also account for group and time fixed effects. You can do that by including these as factors into the regression equation.\n\n<https://www.stata.com/new-in-stata/difference-in-differences-DID-DDD/>\n",
    "supporting": [
      "07_did_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}