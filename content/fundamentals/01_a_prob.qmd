---
title: "Probability Theory"
linktitle: "Probability Theory"
date: "2022-11-23"
output:
  blogdown::html_page:
    toc: true
menu:
  example:
    parent: Fundamentals
    weight: 1
type: docs
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.width = 6, fig.asp = 0.618, fig.align = "center", fig.retina = 3, out.width = "75%")
set.seed(11)
options("digits" = 2, "width" = 150)
options(dplyr.summarise.inform = FALSE)

# custom ggplot theme
# colors from TUHH brand identitiy
tuhh_colors <- c("#D0D0CE", "#00C1D4", "#FF4F4F", "#5AFFC5",
                 "#FFDE36", "#143BFF", "#FF7E15", "#FFAEA2")

# initialise theme
cds_theme <- ggthemr::define_palette(
  swatch = tuhh_colors,
  gradient = c(lower = "#FFAEA2", upper = "#00C1D4"),
  background = "#0F2231",
  line = c("#FFFFFF", "#FFFFFF"),
  text = c("#FFFFFF", "#FFFFFF"),
  gridline = c(ggplot2::alpha("#D0D0CE", 0.2), 
               ggplot2::alpha("#D0D0CE", 0.4))
)

# set theme
ggthemr::ggthemr(cds_theme, type = "outer")

# source custom DAG theme
source("../../code/dag_theme.R")
```

# Introduction

Before we dive into topics of causal inference, we review some basic concepts of probability and statistics. All methods that we will use later in this course are based on statistical models and these require probability theory. But we will keep it as short as possible as our focus and learning goal lies more on applications and coding than on the theoretical part.

# Probability

First, we will review some basic concepts of probability theory.

## **Basic rules of probability**

Consider the most simple example: flipping coins. We define the flip of a coin as a **random variable** as we don't know the outcome. To express our uncertainty, we make us of probability theory.

Flipping the coin, we will see how the coin has landed and our random variable can take on of the **two possible events** $\{H, T\} \subseteq \Omega$. It will be either *Head* or *Tail*.

So we have already defined two terms: random variable and events. Now what is a probability? A **probability is always linked to an event** typically denoted by a capital letter, here either $H$ and $T$, and expresses **how likely this event is to happen**. Probabilities are always between 0 and 1 and for flipping the coin, as long as it is a fair coin (which we assume), the probabilities are

$$
P(H) = P(T) = 0.5
$$

[Extreme cases]{.underline}: If an event $A$ is impossible, its probability is $P(A) = 0$ and if it is certain to occur, it is $P(A)=1)$.

::: callout-important
**Axiom 1:** Probability is a real number greater or equal to 0.
:::

We can also introduce the **compliment** $\overline{A}$, which is what happens when $A$ does not happen and consequently, $P(A) + P(\overline{A}) = 1$. $A$ and $\overline{A}$ are mutually exclusive, by definition. But there could also be two events $A$ and $B$ that are mutually exclusive, i.e. only one of those events can happen, then $P(A \cup B) = P(A) + P(B)$, where $\cup$ represents the union of both events. The probability of either event happening is equal to the sum of the individual probabilities. For example,

$$
P(H \cup T) = P(H) + P(T) = 1
$$

which shows two things, that the total probability is equal to 1 and that the probability of mutually exclusive events is the sum of the individual probabilities.

::: callout-important
**Axiom 2:** Total probability is equal to 1.
:::

::: callout-important
**Axiom 3:** Probability of mutually exclusive events is the sum of the probabilities.
:::

To understand what not mutually exclusive events are, consider events $studying$ and $working$. For a random person, we don't know what values these random variables take on. But we know the probability for the event that someone is studying or someone is working. And there are also individuals who do both or neither.

Then, the probability of both events happening is calculated by

$$
P(A \cup B) = P(A) + P(B) + P(A \cap B)
$$

with $P(A \cap B)$ being the intersection of both events, i.e. the probability of both studying and working. This formula is based on the **addition rule**.

![](/images/01_venn_excl.png){fig-align="center" width="550"}

For mutually exclusive events:

$$
P(A \cup B) = P(A) + P(B) + P(A \cap B) = P(A) + P(B)
$$

The aforementioned intersection $P(A \cap B)$ can be calculated by the **multiplication rule**,

$$
P(A \cap B) = P(A|B) * P(B) = P(B|A) * P(A)
$$

where $P(A|B)$ denotes the probability of $A$ happening given that $B$ has happened. It is called a **conditional probability** and is defined by:

$$
P(A \mid B) = \frac{P(A \cap B)}{P(B)}
$$

It can be thought of as the probability of an event $A$ after you know that $B$ is true. Essentially, it computes the possibility of event $A$ and $B$, normalized by the probability of $B$ occurring. The conditional probability is crucial when talking about causality which you will later see as it for example yields probabilities for specific groups.

Using the example with workers and students: without knowing exact numbers, we can almost safely assume that students are less likely to work than individuals who are not studying.

$$
P(working|studying) > P(working|\overline{studying})
$$

Essentially, we are looking at probabilities restricted to a subset of the sample.

Another important concept when dealing with probabilities of events is **stochastic independence**. In case of two events being independent, the conditional probability is equal to the probability of the event happening anyways:

$$
P(A \mid B) = P(A)
$$

A typical example of independence is to roll a die twice. The second roll does not depend on the first one and each outcome is as likely independent of the first roll. This also results in

$$
P(A \cap B) = P(A) \ P(B)
$$

## **Probability Tree**

An intuitive way to think about (conditional) probabilities is a probability tree. Branches from one node always sum to $1$ in probability as one (and only one) of the events has to happen. The probability of two consecutive events is obtained by multiplying the probabilities.

Consider the following example: you are project manager and based on your are interested in th probability of a project being delivered on time. Based on your experience, you know that whether a project is on time depends on whether there is a change in scope. Based on your historical data about past projects, you come up with the following tree.

![Probability tree](/images/01_tree.png){fig-align="center" width="450"}

https://www.mashupmath.com/blog/probability-tree-diagrams

https://en.wikipedia.org/wiki/Tree_diagram\_%28probability_theory%29#/media/File:Probability_tree_diagram.svg

*https://eight2late.wordpress.com/2010/03/11/bayes-theorem-for-project-managers/*

## Assignment 1

Define being on time as event $T$, being not on time as $\overline{T}$, having a change in scope as $S$ and having no change in scope as $\overline{S}$. Then, compute the following probabilities:

-   $P(T \cap S)$

-   $P(T \cap \overline{S})$

-   $P(\overline{T} \cap S)$

-   $P(\overline{T} \cap \overline{S})$

What is the sum of all four probabilities?

## **Set Theory**

Another useful tool to visualize the occurrence and relationship between events are Venn diagrams building on set theory. A very simple one we actually already used above to illustrate the difference of mutually exclusive and non-mutually exclusive events.

Let's use an example to understand the other rules mentioned above using a Venn diagram: suppose you are working in a company that has developed an application available on three different kind of devices, smartphones, tables and computers. So far your pricing plan is very simple and you have just charged the same amount from all customers, regardless of what and how many devices they use.

But now you want to review your pricing plan and evaluate whether it could make sense to offer pricing plans that differ in the device and number of maximum devices that can be used per account. So first of all you collect usage data of a random sample of 1000 customers from the last month to get an idea of the current distribution.

::: callout-note
| `library()` loads external packages/libraries containing functions that are not built in base `R`.
:::

::: callout-note
| `tibble()` is the most convenient way to create tables. You specify column name and content and assign your `tibble` to an object to store it.
:::

::: callout-note
| `ifelse(test, yes, no)` is a short function for if...else statements. The first argument is a condition that is either `TRUE` or `FALSE` and determines whether the second or third argument is returned.
:::

::: callout-note
| `rbinom(n, size, prob)` samples `n` values from a binomial distribution of a given `size` and with given probabilities `prob`.
:::

::: callout-note
| `mutate()` is one of the most important functions for data manipulation in tables. It is used to either create or change variables/columns. You provide the column name (new or existing) and then specify how to create or change the values in that specific column. For example, `mutate(table, new_variable = existing_var / 100)`, which is equivalent to `table %>% mutate(new_variable = existing_var / 100)`.
:::

!!! exclude creation and move R explanations

```{r}
# Load tidyverse package
library(tidyverse)

# Nmber of obervations
n <- 1000

# Create tibble
app_usage <- tibble(
  # Create user_id in increasing order
  user_id = 1:n,
  # Randomly sample if smartphone was used
  smartphone = rbinom(n, 1, 0.4),
  # Sample if tablet was used. More likely if smartphone was not used.
  tablet = ifelse(smartphone == 1, rbinom(n, 1, 0.2), rbinom(n, 1, 0.5)),
  # Sample if computer was used. More likely if tablet was not used.
  computer = ifelse(tablet == 1, rbinom(n, 1, 0.1), rbinom(n, 1, 0.3))
)

# If no device has value of 1, we set smartphone to 1
app_usage <- app_usage %>%
  rowwise() %>% 
  mutate(smartphone = ifelse(sum(smartphone, tablet, computer) == 0, 1, smartphone))
```

Here, we simulated some artificial data. Seeing the formulas used for constructing the data, we already know that e.g. customers tend not to use the app on both tablet and computer.

::: callout-note
| To see the first lines of a table (for example a `tibble()` or a `data.frame()`, you can use the `head(table, n)` function, where `n` specifies how many rows you want to see.
:::

```{r}
head(app_usage, 10)
```

A general overview of total customers per device category shows that in the smartphone category there are the most users and in the computer category there are the least.

::: callout-note
| Summing all values by column is done by `colSums(table)`. For rows, you would use `rowSums(table)`.
:::

```{r}
colSums(app_usage)
```

Summing the $user\_id$ does not make any sense. We could ignore it, but we can also just access the columns we want to sum. There are several ways.

::: callout-note
| To access only specified columns, you can provide the location or names in square brackets or you can use the `select()` function.
:::

```{r}
# equivalent commands
#colSums(app_usage[, 2:4])
#colSums(app_usage[, c("smartphone", "tablet", "computer")])
app_usage %>% select(smartphone, tablet, computer) %>% colSums()
```

Now let's see what the Venn diagram says, which is a diagram showing the relation between sets. We can see the union, intersection differences and complements in the diagram.

::: callout-note
| `which()` checks a condition and returns the indices.
:::

```{r}
set_phon <- which(app_usage$smartphone == 1)
set_tabl <- which(app_usage$tablet == 1)
set_comp <- which(app_usage$computer == 1)
sets_all <- list(set_phon, set_tabl, set_comp)

library(ggVennDiagram)
ggVennDiagram(sets_all, category.names = c("Smartphone", "Tablet", "Computer"),
              label_percent_digit = 2) +
  theme(legend.position = "none", 
        panel.background = element_rect("grey"),
        strip.background = element_rect("grey")) +
  scale_x_continuous(expand = expansion(mult = .24))
```

![Generic Venn diagram](/images/01_venn_diag.png){fig-align="center" width="350"}

Using the Venn diagram, we are able to answer questions like the following:

-   What is the percentage of customers using all three devices?

-   What is the percentage of customers using at least two devices?

-   What is the percentage of customers using only one device?

Try to answer these questions yourself.

::: {.callout-caution collapse="true"}
## Answers

-   0.5%

-   7.3% + 3.3% + 8.8% + 0.5%

-   10% + 42.3% + 27.8%
:::

We can also use the example to go through the basic probability rules defined above.

**Addition rule**:

What is the percentage of customers using a smartphone, a tablet or both devices?

$P(T \cup S) = P(T) + P(S) - P(T \cap S)$

**Multiplication rule**:

Given that a customer uses a computer, how likely is he/she to use a tablet as well?

$P(T|C) = \frac{P(T \cap C)}{P(C)}$

**Total probability rule**:

What is the fraction of customers using a computer?

$P(C) = P(C \cap T) + P(C \cap \overline{T})$

## **Bayes Theorem**

### Math

A very important theorem in probability theory is **Bayes theorem** that we get by reformulating the multiplication rule

$$
P(A ∩ B) = P(A|B)*P(B) \\
P(B ∩ A) = P(B|A)*P(A)
$$

Using the equality of $P(A ∩ B)$ and $P(B ∩ A)$ we arrive at

$$
P(B|A)*P(A) = P(A|B)*P(B)
$$

and finally at the Bayes theorem:

$$
P(A|B) = \frac{P(B|A)*P(A)}{P(B)} = \frac{P(B|A)*P(A)}{P(B|A)*P(A)+P(B|\overline{A})*P(\overline{A})}
$$

Bayes theorem expresses a conditional probability, exemplary the likelihood of $A$ occurring conditioned on $B$ having happened before.

::: callout-tip
You will often hear Bayes theorem in connection with the terms *updating beliefs*. You start with a prior probability $P(A)$ and collecting evidence $P(B)$ and the likelihood $P(B|A)$, you update your prior probability to get a posterior probability $P(A|B)$. That is in fact the foundation of Bayesian inference. Look it up if you want, but you won't need Bayesian inference for this course.

$$
Posterior = \frac{Likelihood * Prior}{Evidence}
$$
:::

### **Application**

To understand how useful Bayes theorem is, let's use an example: Imagine, you are quality assurance manager and you want to buy a new tool that automates part of the quality assurance. If the tool finds a product it considers faulty, an alarm is triggered. The seller of the tool states that if a product is faulty, the tool is 97% reliable and if the product is flawless, the test is 99% reliable. Also, from your past experience you know that 4% of your products come out with flaws.

To assess the usefulness of the tool in practice you want to know the following probabilities:

1.  What is the probability that when the alarm is triggered the product is found to be flawless?

2.  What is the probability that when the alarm is triggered the product is found to have flaws?

Using Bayes theorem and the formulas will help you to arrive at the correct answers and guide your decision whether to buy the tool.

We should start by defining the events and event sets:

$A$: product is faulty vs. $\overline{A}$: product is flawless

$B$: alarm is triggered vs. $\overline{B}$: no alarm

Also, from our past experience and the producers specifications we already know some probabilities:

$P(B|A) = 0.97$ and consequently $P(\overline{B}|A) = 0.03$

$P(B|\overline{A}) = 0.01$ and consequently $P(\overline{B}|\overline{A}) = 0.99$

$P(A) = 0.04$ and consequently $P(\overline{A}) = 0.96$

Note, that what we are looking for is not the same as what the manufacturer states in his/her specifications. What we are looking for is $P(\overline{A}|B$ (1) and $P(A|B)$ (2) and we will need Bayes theorem to obtain those probabilities.

Let's recall Bayes theorem:

$$
P(A|B) = \frac{P(B|A)*P(A)}{P(B)} = \frac{P(B|A)*P(A)}{P(B|A)*P(A)+P(B|\overline{A})*P(\overline{A})}
$$

### Assignment 2

Compute

-   $P(\overline{A}|B)$ (1)

<!-- -->

-   $P(A|B)$ (2)

and fill the gaps in the following sentence:

*These results show that in case the alarm is triggered, there is still a possibility of about \_\_% that the product is flawless and in only \_\_% of cases the product is faulty.*
