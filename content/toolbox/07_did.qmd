---
title: "Difference-in-Differences"
linktitle: "Difference-in-Differences"
date: "2022-11-23"
output:
  blogdown::html_page:
    toc: true
menu:
  example:
    parent: Toolbox
    weight: 9
type: docs
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.width = 6, fig.asp = 0.618, fig.align = "center", fig.retina = 3, out.width = "75%")
set.seed(11)
options("digits" = 2, "width" = 150)
options(dplyr.summarise.inform = FALSE)

# custom ggplot theme
# colors from TUHH brand identitiy
tuhh_colors <- c("#D0D0CE", "#00C1D4", "#FF4F4F", "#5AFFC5",
                 "#FFDE36", "#143BFF", "#FF7E15", "#FFAEA2")

# initialise theme
cds_theme <- ggthemr::define_palette(
  swatch = tuhh_colors,
  gradient = c(lower = "#FFAEA2", upper = "#00C1D4"),
  background = "#0F2231",
  line = c("#FFFFFF", "#FFFFFF"),
  text = c("#FFFFFF", "#FFFFFF"),
  gridline = c(ggplot2::alpha("#D0D0CE", 0.2), 
               ggplot2::alpha("#D0D0CE", 0.4))
)

# set theme
ggthemr::ggthemr(cds_theme, type = "outer")

# source custom DAG theme
source("../../code/dag_theme.R")
```

# Introduction

Another quasi-experimental method from our toolbox is the **difference-in-differences (DiD)** approach. It is the most popular research design in quantitative and social sciences. As the name implies, the method **captures differences by observing a treatment and a control group over time** to estimate causal average effects.

In its simplest form, DiD compares **two groups** (control and treatment) **at two points in time** (before treatment and after) by observing if and how different both groups change. It is important to note, that both groups do not need to be equal before the treatment.

By taking two differences, **two different kind of biases can be avoided**. First, by comparing both groups at both points in time, any external effect that affects the outcome of both groups in the same way is equalized. Secondly, taking only the difference of a change in consideration, we can disregard selection bias. Potential outcomes can differ:

$$
E[Y_0|D = 0] \gtreqqless E[Y_0|D = 1] 
$$

We don't care whether initially treatment and control group are different. We only assume that they **behave similarly in absence of treatment**.

As can be seen in the table, the difference in outcome for the treatment group before and after treatment is $D + T$, while for the control group it is only $T$. The difference of these two differences then reduces to only $D$, which is the treatment effect we want to estimate.

| Group           | Time | Outcome                   | 1st Difference | DiD |
|-----------------|------|---------------------------|----------------|-----|
| Treatment (D=1) | 0    | $Y= Y_{T=0, D=1}$         |                |     |
|                 | 1    | $Y = Y_{T=0,D=1} + T + D$ | $T +D$         |     |
|                 |      |                           |                | $D$ |
| Control (D=0)   | 0    | $Y = Y_{T=0, D=0}$        |                |     |
|                 | 1    | $Y = Y_{T=0, D=0} + T$    | $T$            |     |

We can also break it down in our known notation:

$$
\delta = ATE = \bigg(E[Y_{D=1}|T=1] - E[Y_{D=1}|T=0] \bigg)- \bigg(E[Y_{D=0}|T=1] - E[Y_{D=0}|T=0]\bigg)
$$

Because there are a lot of subscripts, it can also help to write down the formula in pseudo-math:

$$
ATE = (Y_{Treatment, After} - Y_{Treatment, Before}) - (Y_{Control, After} - Y_{Control, Before})
$$

Again, opposed to methods where we just know one outcome - the "after" outcome, regardless of whether a unit received or did not receive treatment - we do not have to assume that the potential outcomes $E[Y_0|D=1] = E[Y_0|D=1]$ are equal. That is a big difference, because do not have to assume that observation units are similar in all their characteristics.

Instead DiD hinges on a different assumption, the **parallel trends assumption.** It says that, in absence of treatment for both groups, they would be expected to evolve similarly over time. In other words, we do not expect the potential outcome to be similar, but only the change of outcomes from before to after. It implies that there is no factor that has only an impact on just one of the groups. If units differ in characteristics, they are only allowed to have a constant effect. If the effect varies with time, the parallel trends assumption is violated.

# Application

Illustrating the parallel trends assumption is very helpful. By going through two scenarios, we will look at an example where parallel trends are fulfilled and another one where it is violated.

-   **Scenario A**: parallel trends assumption fulfilled

-   **Scenario B**: parallel trends assumption violated

Let's imagine, you are manager of a company that has two stores, one of them being in City 1 and the other being in City 2. You want to test the effectiveness of a local ad campaign on sales. Therefore, you will run a campaign at the store in City 1 but not in City 2 and keep track of sales in the periods before and after the treatment.

You don't need to read follow all steps how to generate data for both scenarios, but I'll leave it in for those who are interested.

::: {.callout-tip collapse="true"}
## Data Simulation

$Y$ - sales

$D$ - true treatment effect

$P$ - periods

$S$ - store index

$X$ - covariate, e.g. ecosystem

With the function *generate_data()* we generate data with arbitrary values for the number of stores, number of observed periods, the size of the true treatment effect, the timing of treatment and level of noise in the data generating process. Data is generated for both scenarios as can be seen at the suffixes.
:::

```{r}
#| message: false
#| code-fold: true
#| code-summary: "Function to simulate DiD data"

# Load tidyverse package
library(tidyverse)

# Function to simulate data
generate_data <- function(
    S = 2, # number of groups
    P = 10, # number of periods
    D_size = 1, # effect of treatment
    D_time = NULL, # time of treatment
    y_0 = 50, # base value for y
    sd = 1, # standard deviations for randomly generated sequences
    scenario = c("A", "B")
){
  # create group period dyads
  s <- rep(0:1, each = P)
  p <- rep(1:P, S)
  
  # timing and size of treatment (effect)
  delta <- D_size
  if (missing(D_time)) D_time <- P/2
  after <- as.numeric(ifelse(p > D_time, 1, 0))
  
  # create relation between independent variables and treatment (actually
  # other way round, but easier to simulate this way)
  x1 <- rnorm(S*P, s, sd)
  
  # create dependent variable ...
  # ... for scenario (A)
  y_a <- y_0 + delta*s*after + 1/5*p + x1 + rnorm(S*P, 0, sd)
  
  # ... for scenario (B)
  y_b <- y_0 + delta*s*after + 1/5*p + x1 + s*x1 + 1/3*p*x1 + rnorm(S*P, 0, sd)
  
  # add variables to table
  df <- tibble(
    treat   = s,
    period  = p,
    after   = after,
    x1      = x1,
    sales   = if (scenario == "A") {y_a} else {y_b}
  )
  
  # return table
  return(df)
}
```

We choose to generate a data set with a true treatment effect of 1 and 10 observed periods. For now, we just have one store as a treated unit and one store as a non-treated unit. Later, we will extend it to a larger number of stores per group, but for demonstration purpose, we restrict it to two stores, initially. We have 10 periods with 5 periods before and 5 after treatment. Lastly, we add a little bit of noise.

```{r}
# Generate one sample for each scenario
P     <- 10 # number of periods
delta <- 1  # true treatment effect

# Scenario A
df_A <- generate_data(P = P, D_size = delta, sd = 0.01, scenario = "A")

# Scenario B
df_B <- generate_data(P = P, D_size = delta, sd = 0.01, scenario = "B")
```

## Parallel trends

### Scenario A

To compute an estimated treatment effect, we filter the data to the two periods just around treatment and implement the formulas as in the introduction. Not surprisingly, we get an estimate that is very close to our true treatment effect.

```{r}
# [1.1.1] (A) Fulfillment ----
# Scenario (A)
# Only show last data point before and first data point after treatment.
df_A_zoom_in  <- df_A %>% filter(period %in% (P/2):(P/2+1))

# Manually compute differences
# Step 1: Difference between treatment and control group BEFORE treatment
before_control_A <- df_A_zoom_in %>%
  filter(treat == 0, after == 0) %>% 
  pull(sales)
before_treatment_A <- df_A_zoom_in %>%
  filter(treat == 1, after == 0) %>% 
  pull(sales)

diff_before_A <- before_treatment_A - before_control_A

# Step 2: Difference between treatment and control group AFTER treatment
after_control_A <- df_A_zoom_in %>%
  filter(treat == 0, after == 1) %>% 
  pull(sales)
after_treatment_A <- df_A_zoom_in %>%
  filter(treat == 1, after == 1) %>% 
  pull(sales)

diff_after_A <- after_treatment_A - after_control_A

# Step 3: Difference-in-differences. Unbiased estimate if parallel trends is 
# correctly assumed and there is no hidden confounding. Estimate may vary from 
# true treatment effect, as we also include some noise in the data generating 
# process.
diff_diff_A <- diff_after_A - diff_before_A
sprintf("Estimate: %.2f, True Effect: %.2f", diff_diff_A, delta)
```

Looking at the last period before and the first period after treatment, the impact of treatment can clearly be seen. The dashed line represents the counterfactual value for the treated group, i.e. the value it would have if it had not been treated. This value is not observed, but by the parallel trends assumptions, it would have developed like the value for the untreated group.

::: callout-tip
## Plots in this chapter

Generating the plots for this chapter is a bit tricky as they contain a lot of annotations and other extensions. I left the code for those who want to replicate it. But you do not worry if you cannot reproduce them.
:::

```{r}
#| code-fold: true
#| code-summary: "Plot parallel trends assumption"
#| message: false
#| fig-cap: "If parallel trends assumption can be assumed, treatment effect is valid. Counterfactual line shows how outcome would have been evolved in absence of treatment."

# Compute counterfactual sales for treated group
cf_treat_A <- df_A[!df_A$treat == 1, "sales"] + diff_before_A
df_A[df_A$treat == 1, "sales_cf"] <- cf_treat_A

# Add to zoomed in table
df_A_zoom_in <- df_A_zoom_in %>% left_join(df_A)

# Plot DiD with parallel trends assumption
ggplot(df_A_zoom_in, aes(x = period, y = sales, color = as.factor(treat))) +
  # Geographic elements
  geom_line() +
  geom_vline(xintercept = P/2 + .5, color = ggthemr::swatch()[5]) + 
  geom_line(data = df_A_zoom_in %>% filter(treat == 1),
            aes(x = period, y = sales_cf),
            color = ggthemr::swatch()[3], alpha = .8, linetype = "dashed") +
  annotate(geom = "segment", x = (P/2+1), xend = (P/2+1),
           y = after_treatment_A, yend = after_treatment_A - diff_diff_A,
           linetype = "dashed", color = ggthemr::swatch()[4], linewidth = 1) +
  annotate(geom = "label", x = (P/2) + 0.9, 
           y = after_treatment_A - (diff_diff_A / 2), 
           label = "Treatment effect", size = 3, fill = ggthemr::swatch()[4]) +
  annotate(geom = "text", x = (P/2) + 0.7, 
           y = before_control_A + 1.1*diff_before_A + .1, 
           label = "Counterfactual", size = 4, 
           angle = 3, color = ggthemr::swatch()[3]) +
  # Custom scaling and legend
  scale_x_continuous(name ="", breaks=c(5, 5.5, 6),
                     labels = c("Before\n Treatment", 
                                "Treatment",
                                "After\n Treatment")) +
  scale_color_discrete(labels = c("Control Group", "Treatment Group")) +
  guides(colour = guide_legend(reverse = T)) +
  theme(legend.title = element_blank()) +
  ggtitle("Scenario A:\nParallel Trends Assumption")
```

### Scenario B

Repeating the steps for scenario B yields an unexpected result. The estimated treatment effect is different from what we would have expected.

```{r}
# [1.1.2] (B) Violation ----
# Scenario (B)
# Only show last data point before and first data point after treatment.
df_B_zoom_in  <- df_B %>% filter(period %in% (P/2):(P/2+1))

# Manually compute differences
# Step 1: Difference between treatment and control group BEFORE treatment
before_control_B <- df_B_zoom_in %>%
  filter(treat == 0, after == 0) %>% 
  pull(sales)
before_treatment_B <- df_B_zoom_in %>%
  filter(treat == 1, after == 0) %>% 
  pull(sales)

diff_before_B <- before_treatment_B - before_control_B

# Step 2: Difference between treatment and control group AFTER treatment
after_control_B <- df_B_zoom_in %>%
  filter(treat == 0, after == 1) %>% 
  pull(sales)
after_treatment_B <- df_B_zoom_in %>%
  filter(treat == 1, after == 1) %>% 
  pull(sales)

diff_after_B <- after_treatment_B - after_control_B

# Step 3: Difference-in-differences. Unbiased estimate if parallel trends is 
# correctly assumed and there is no hidden confounding. Estimate varies from 
# true treatment effect due to confounding and added noise.
diff_diff_B <- diff_after_B - diff_before_B
sprintf("Estimate: %.2f, True Effect: %.2f", diff_diff_B, delta)
```

Again, the picture is very similar. Having only four data points, treatment before and after and control before and after, there is no way to test the parallel trends assumption which leaves room for doubt. So how can we check whether we made a mistake or the parallel trends assumption is violated?

```{r}
#| code-fold: true
#| code-summary: "Plot parallel trends assumption"
#| message: false
#| fig-cap: "Knowing the true treatment effect, we know that the estimated treatment effect is too high. But this plot can't tell us why."

# Compute counterfactual sales for treated group
cf_treat_B <- df_B[!df_B$treat == 1, "sales"] + diff_before_B
df_B[df_B$treat == 1, "sales_cf"] <- cf_treat_B

# Add to zoomed in table
df_B_zoom_in <- df_B_zoom_in %>% left_join(df_B)

# Plot DiD with parallel trends assumption
ggplot(df_B_zoom_in, aes(x = period, y = sales, color = as.factor(treat))) +
  # Geographic elements
  geom_line() +
  geom_vline(xintercept = P/2 + .5, color = ggthemr::swatch()[5]) + 
  geom_line(data = df_B_zoom_in %>% filter(treat == 1),
            aes(x = period, y = sales_cf),
            color = ggthemr::swatch()[3], alpha = .8, linetype = "dashed") +
  annotate(geom = "segment", x = (P/2+1), xend = (P/2+1),
           y = after_treatment_B, yend = after_treatment_B - diff_diff_B,
           linetype = "dashed", color = ggthemr::swatch()[4], linewidth = 1) +
  annotate(geom = "label", x = (P/2) + 0.9, 
           y = after_treatment_B - (diff_diff_B / 2), 
           label = "Treatment effect", size = 3, fill = ggthemr::swatch()[4]) +
  annotate(geom = "text", x = (P/2) + 0.7, 
           y = before_control_B + 1.1*diff_before_B + .1, 
           label = "Counterfactual", size = 4, 
           angle = 3, color = ggthemr::swatch()[3]) +
  # Custom scaling and legend
  scale_x_continuous(name ="", breaks=c(5, 5.5, 6),
                     labels = c("Before\n Treatment", 
                                "Treatment",
                                "After\n Treatment")) +
  scale_color_discrete(labels = c("Control Group", "Treatment Group")) +
  guides(colour = guide_legend(reverse = T)) +
  theme(legend.title = element_blank()) +
  ggtitle("Scenario B:\nParallel Trends Assumption")
```

## Event Study

Hence, numerous researchers endeavor to enhance the reliability of their findings through the utilization of an event study. Comparing trends before treatment across treatment and control group, it should show that there was no difference prior to the treatment. **Because if there was no difference before treatment, why should there be difference after the treatment (if not for the treatment itself)?**

However, event studies cannot provide full certainty about the parallel trends assumption. There still might be other unobserved factors that could affect the treatment. But still, it is a good way to argue that treatment and control group are comparable.

```{r}
#| code-fold: true
#| code-summary: "Code: Event Study A"

# [1.2] Event study ----
# To provide evidence of the credibility in assuming parallel trends, 
# researchers often perform an event study, if possible. Instead of only
# looking at the last period before and the first period after treatment,
# further periods are included to examine the validity of the parallel trends
# assumption and the treatment effect estimate.

# [1.2.1] (A) Fulfillment ----
# Zoom out and show that parallel trend assumption is fulfilled in scenario (a)

# Compute difference in control group
diff_control_A <- after_control_A - before_control_A

# Plot event study
ev_stdy_A <- ggplot(df_A, aes(x = period, y = sales, color = as.factor(treat))) +
  geom_line() +
  geom_vline(xintercept = P/2 + .5, color = ggthemr::swatch()[5]) + 
  geom_line(data = df_A %>% filter(treat == 1, period >= P/2),
            aes(x = period, y = sales_cf),
            color = ggthemr::swatch()[3], linetype = "dashed") +
  annotate(geom = "segment", x = (P/2+1), xend = (P/2+1),
           y = after_treatment_A, yend = after_treatment_A - diff_diff_A,
           linetype = "dashed", color = ggthemr::swatch()[4], linewidth = 1) +
  # Custom scaling and legend
  scale_x_continuous(breaks = 1:P) +
  scale_color_discrete(labels = c("Control Group", "Treatment Group")) +
  guides(colour = guide_legend(reverse = T)) +
  theme(legend.title = element_blank()) +
  ggtitle("Scenario A\nEvent Study")
```

```{r}
#| code-fold: true
#| code-summary: "Code: Event Study B"

# [1.2.2] (B) Violation----
# Zoom out and show that parallel trend assumption is violated in scenario (b)

# Compute difference in treatment group
# Before treatment
diff_control_B <- after_control_B - before_control_B

# Increase from t0 to before treatment
init_treatment_B <- df_B %>%
  filter(treat == 1, period == 1) %>%
  pull(sales)
diff_treatment_B <-  (before_treatment_B - init_treatment_B) / (P/2)

# Plot event study
ev_stdy_B <- ggplot(df_B, aes(x = period, y = sales, color = as.factor(treat))) +
  geom_line() +
  geom_vline(xintercept = P/2 + .5, color = ggthemr::swatch()[5]) + 
  geom_line(data = df_B %>% filter(treat == 1, period >= P/2),
            aes(x = period, y = sales_cf),
            color = ggthemr::swatch()[2], linetype = "dashed") +
  annotate(geom = "segment", x = (P/2),
           xend = P,
           y = before_treatment_B,
           yend = before_treatment_B + (P/2)*(diff_treatment_B),
           linetype = "dashed", color = ggthemr::swatch()[3]) +
  # Estimated treatment effect
  annotate(geom = "segment", x = (P/2+1), xend = (P/2+1),
           y = after_treatment_B, yend = after_treatment_B - diff_diff_B,
           linetype = "dashed", color = ggthemr::swatch()[4], linewidth = 1) +
  # Custom scaling and legend
  scale_x_continuous(name   = "Period", breaks = 1:P) +
  scale_y_continuous(name = "Sales") +
  scale_color_discrete(labels = c("Control Group", "Treatment Group")) +
  guides(colour = guide_legend(reverse = T)) +
  theme(legend.title = element_blank()) +
  ggtitle("Scenario B\nEvent Study")
```

```{r}
#| layout-nrow: 1
#| echo: false
#| fig-cap: 
#|  - "For treatment and control group, we see the same trend over time. This lends credibility to the parallel trends assumption and consequently, to the validity of the causal treatment effect."
#|  - "Other than in scenario A, the parallel trends assumption does not seem to hold. The estimated treatment effect is larger than the actual treatment effect. This is due to different trends in both groups. The treatment group has a more positive trend even without treatment and the groups would have further diverged after treatment (see dashed red line). The difference between the dashed red and dashed blue line is attributable to this trend and should not be part of the treatment effect."

ev_stdy_A
ev_stdy_B
```

## Modeling

A more typical situation is usually that there is more than one unit in the treatment and control group. You could e.g. imagine that you are managing more than two stores and are implementing an ad campaign in a specific region.

To simulate such a scenario, we generate data for 3'000 stores that are split evenly into two regions. In one region, the ad campaign will be run (treatment region) and in the other there will be no campaign (control region). The variable relationships as defined in the previous section still hold.

```{r}
# [1.4] Linear regression ----
# Now assume that there are more than two stores and treatment is performed
# in a specific region which is, depending on scenario (A) and (B) 
# different to the control region.

# Generate a bunch of samples and combine in one table. Here, we choose a higher
# standard deviation.
# We assume that we only have data from one period prior and one period after 
# treatment.
n_stores <- 3e+3

# Scenario A
df_A_lm  <- lapply(1:n_stores, function(R) {
  generate_data(sd = 1, scenario = "A")}) %>%
    bind_rows() %>%
  filter(period %in% (P/2):(P/2+1))

# Scenario B
df_B_lm  <- lapply(1:n_stores, function(R) {
  generate_data(sd = 1, scenario = "B")}) %>%
  bind_rows() %>%
  filter(period %in% (P/2):(P/2+1))
```

### Scenario A

So how do we compute the average treatment effect? Previously in this chapter, we just used basic math calculations (particularly subtraction). But there is an easier way: we can use regression again. This is because the average treatment effect is the coefficient of the interaction of group and time.

$$
y_i = \beta_0 + \beta_1 * Period_i + \beta_2 * Treatment_i + \beta_3 * (Time_i \times Treatment_i) + \epsilon_i
$$

$Time$ indicates whether the period is before or after the treatment and $Treatment$ whether an observation belongs to the treatment group. We can interpret the estimated coefficient $\hat\beta_1$ as the time effect for both groups, it indicates how the outcome evolves without treatment. $\hat\beta_2$ represents the time-invariant level difference between groups, it is positive when the treatment group initially exhibited a higher outcome level.

What we are primarily interested in is the interaction $Time \times Treatment$ and its estimate $\hat\beta_3$. It is only active for the treatment group after the treatment ($Time = 1$, $Treatment=1$) and represents the average treatment effect.

For scenario A, we can see that there is no need to adjust for the covariate $x1$. You could for example think of $x_1$ as the purchase power of the respective region. If you check the formulas again, your will notice that $x1$ has a constant and time-invariant effect on sales and therefore it does not violate the parallel trends assumption.

Including or leaving out $x1$ in the regression yields a very similar unbiased estimate (close to defined true size) for our variable of interest $store:after$, the parameter of interest.

```{r}
# [1.4.1] (A) ----
# (a): Due to the construction of the data set, we expect interaction
# coefficient to be significant as well as the covariate and period. However, as
# the covariate does not have a time-varying effect, it is not a confounder and
# interaction coefficient should be unbiased even if not adjusting for the
# covariate.
summary(lm(sales ~ treat*after , data = df_A_lm))
summary(lm(sales ~ treat*after + x1, data = df_A_lm))
```

### Scenario B

In scenario B, the effect of $x_1$ is different because it has a time-varying effect. Therefore it violates the parallel trends assumption, leading to a biased estimate if $x_1$ is not included (e.g. because it is unobserved).

Because we constructed the data set ourselves, we are able to see that the bias in fact is quite large and the treatment effect seems to include the actual treatment effect plus the effect of $x_1$.

```{r}
# [1.4.2] (B) ----
# (b): Due to the construction of the data set, we expect interaction coefficient
# to be significant and accurate only when adjusting for the time-varying effect
# of the covariate and main effects for period and covariate.
summary(lm(sales ~ treat*after, data = df_B_lm))
```

Only with including $x_1$ and as a main effect and moderator, we can reconstruct the true treatment effect.

```{r}
# Including time-varying effect
summary(lm(sales ~ treat*after + after*x1 + treat*x1, data = df_B_lm)) # best
```

# Conclusion

DiD is a useful quasi-experimental method that relies on the parallel trends assumption which is untestable. We can't prove it but try to justify it by for example showing prior trends. If both groups were evolving similarly before the treatment, that supports the plausibility and appropriateness of using DiD.

DiD is a very actively researched methods and can be extended too many scenarios: e.g. the synthetic control method, that is able to deal with one treated and multiple untreated groups. By matching and weighting the untreated groups, a synthetic group is composed, that is similar in the lead up to the treatment period. It shares similarities with what we have done in the matching chapter. Sometimes you also might end up with many treatment groups and variation in treatment timing. Although you have to be careful with your assumptions and specifications, such cases can also be incorporated into a DiD framework.

# Assignment

Imagine, you are manager of a large health provider that manages many hospitals and you want to test how a new admission procedure affects patient satisfaction. You randomly selected 18 hospitals that introduced the new admission procedure and compare them to 28 other hospitals that did not introduce the method. For both groups of hospitals you collected data from before and after the introduction. The data you have collected is from patient surveys where they were asked how satisfied they are.

Load the data from the file `hospdd.rds`[^1]. Then, perform a difference-in-differences analysis by

[^1]: Data and example from: <https://www.stata.com/new-in-stata/difference-in-differences-DID-DDD/>

1.  Manually computing the mean satisfaction for treated and control hospitals before and after the treatment. Helpful functions could be `filter()`, `pull()` and basic arithmetic operations.

2.  Using a linear regression to compute the estimate. Also, include group and time fixed effects in the regression, i.e. one regressor for each month and one regressor for each hospital: Consider, whether you want to include them as

    -   `month + hospital` or as

    -   `as.factor(month) + as.factor(hospital)`

    and explain what the difference is.

::: callout-warning
## How to submit your solutions!

Please see [here](https://owmork.github.io/causal_ds/submission/submission.html) how you have to successfully submit your solutions. I would recommend you to solve the assignments first in `.R` scripts and in the end convert them to the required format as explained in the submission instructions.
:::
