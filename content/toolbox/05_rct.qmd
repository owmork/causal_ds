---
title: "Randomized Controlled Trials"
linktitle: "Randomized Controlled Trials"
date: "2022-11-23"
output:
  blogdown::html_page:
    toc: true
menu:
  example:
    parent: Toolbox
    weight: 6
type: docs
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.width = 6, fig.asp = 0.618, fig.align = "center", fig.retina = 3, out.width = "75%")
set.seed(11)
options("digits" = 2, "width" = 150)
options(dplyr.summarise.inform = FALSE)

# custom ggplot theme
# colors from TUHH brand identitiy
tuhh_colors <- c("#D0D0CE", "#00C1D4", "#FF4F4F", "#5AFFC5",
                 "#FFDE36", "#143BFF", "#FF7E15", "#FFAEA2")

# initialise theme
cds_theme <- ggthemr::define_palette(
  swatch = tuhh_colors,
  gradient = c(lower = "#FFAEA2", upper = "#00C1D4"),
  background = "#0F2231",
  line = c("#FFFFFF", "#FFFFFF"),
  text = c("#FFFFFF", "#FFFFFF"),
  gridline = c(ggplot2::alpha("#D0D0CE", 0.2), 
               ggplot2::alpha("#D0D0CE", 0.4))
)

# set theme
ggthemr::ggthemr(cds_theme, type = "outer")

# source custom DAG theme
source("../../code/dag_theme.R")
```

# Introduction

Let's recall the **fundamental problem of causal inference**: we are not able to observe individual treatment effects. Only one potential outcome can be observed because there is only one state of the world.

Arguably, the most promising way to deal with this problem is randomization of the observation units and in particular randomized experiments, also known as randomized controlled trials (RCTs). Due to their statistical rigor and simplicity, RCTs are called the **gold standard of causal inference**.

RCTs do not solve the fundamental problem of only observing one potential outcome but instead **treatment and control group are randomized** such that both groups are expected to be almost equal. Having similar groups that either received or not received treatment, we can calculate a valid causal estimate, the **Average Treatment Effect (ATE)**. But it is only due to the randomization of observation units (e.g. individuals) that we are able to interpret it causally. If you remember the example with parking spots from a previous chapter, the computed $ATE$ can also return invalid estimates.

# Estimation

Let's go into detail what needs to be ensured for a valid estimation, how to randomize treatment objects and how perform estimation.

## Identification

Two assumptions are crucial for the ATE to be interpreted causally.

### Independence assumption

We have to assume **independence between the potential outcomes and the treatment assignment**, i.e. treatment assignment to a unit hast nothing to do with the size of treatment effect for a unit. In other words, it is not only those in the treatment group who benefit the most or the least from the treatment.

$$
D_i \perp (Y_{i0}, Y_{i1})
$$

This is where we exploit randomization. We can actually **ensure** that there is **no association between potential outcomes and treatment by randomly assigning observation units** to control and treatment group.

This way, **both groups will be very similar on average**, both in observed and in unobserved characteristics. They will **only differ in their treatment status and possibly in the observed outcome**, which makes the estimation of a causal effect possible.

Please make sure, that you understand the formula correctly. It does not mean that there is no treatment effect. The (potential) outcome under $D=0$ or $D=1$ is not affected by whether a particular observation unit does or does not receive the treatment. However, the observed outcome $Y_i$ might depend on $D_i$, and in fact, that is the effect we are interested in.

A related way to express it is

$$
E[Y_0|D=0] = E[Y_0|D=1]
$$

Regardless of the treatment value a unit receives, the expected (but not always observed) potential outcome is the same in both treatment ($D=1$) and control group ($D=0$). The **mean potential outcome** is **equal for both groups**.

This does also imply equality of ATE and ATT, as there is no bias and the **association** we see is **equal to the causation**. Remember, we saw that $ATE \neq ATT$ when there is selection bias, i.e. observation units chose to be treated or not to be treated. But in case of randomization, by definition, selection bias cannot occur.

**When is the independence assumption violated?**

An example, where the independence between treatment and potential outcomes is not given is if the treatment assignment is not randomized but people are able to self-select into on of the groups.

Then, it could happen that for e.g. more motivated people would choose the treatment and when motivation had an impact on the potential outcome, e.g. more motivated people have a higher outcome for both potential outcomes compared to less motivated people, that are more likely to be in the control group. Under these circumstances, the independence assumption would be violated.

### SUTVA

The second assumption that needs to be fulfilled is the stable unit treatment value assumption (SUTVA).

It ensures that there is **no interference between units**. In other words, one unit's treatment does not affect outcomes of other units. If unit $i$ received a treatment, than this treatment of unit $i$ should have no effect on another unit.

Implicitly, the assumption states that there are **only two potential outcomes for each unit** and they only depend on a unit's own treatment status.

**When is the SUTVA violated?**

In situations where observation units are somehow clustered like e.g. in classrooms, departments or other kind of groups, violations of SUTVA can occur.

As an example, imagine you are running a company and select a few of your employees to participate in a program that teaches them about safety measures. After the program, it is very likely that they share some of the program content with their colleagues in their department, who might not have been selected for participation. Then, there are spillover effects.

To deal with violations of SUTVA you could change your selection process or change the level of analysis (analyzing clusters instead of individuals).

## Randomization

In practice, randomization is done automatically by software programs but to get an intuition, you could also think of it as e.g. flipping a coin for each observation unit or individual and assigning units that get head to the treatment group, while units that get tail are assigned to the control group (or the other way around).

In fact, that is already a special case because the probability of being treated and being not treated is 50% for both cases. But treatment probabilities could also take different values for a variety of reasons, for example because treatment is costly. However, you need to ensure that both groups are large enough to be comparable in order to fulfill the independence assumption.

Let's see what that means. We assume that we have a population of 10'000 individuals which we want to learn something about. Using `runif()` and `rbinom()`, we synthetically generate this population with random values for the characteristics $age$ and $sex$.

```{r}
#| message: false

# Load tidyverse package
library(tidyverse)

# Define population size
n <- 1e+4 

# Create population with two characteristics
X <- tibble(
  age = runif(n, 18, 65), # draw random values from uniform distribution
  sex = rbinom(n, 1, 0.5) # draw random values from binomial distribution
)

# Show table
X
```

Until now, we have not assigned units to treatment and control group and actually, we do not want to assign our whole population to any group. As a matter of fact, in many applications, you are just able to draw a sample from the population and almost never the whole population.

Remember, randomization of treatment should achieve that we are able to interpret the average treatment effect causally and for that, both groups need to be as similar as possible. The image illustrates the randomization process. Try to think what could happen if you have just very few units in both groups. How likely is is that they are very similar regarding their characteristics? You can probably already sense that this might not be sufficient to make groups comparable.

![Illustration of randomization process](/images/05_rand.png){fig-align="center" width="350"}

But let's try it out and see how average group characteristics develop when we change the sample size.

In R, it is very easy to generate a random vector that we can use for randomization. Here, we want to have a random vector that contains either 1 (treatment group) or 0 (control group) with a treatment probability of 50%. We can make use of the `rbinom()` function that can randomly generate outcomes of a Bernoulli trial, which you can just imagine as flipping the coin $n$ times.

As we have 10'000 people in our population, we will vary sample sizes from 10 to 10'000 to understand the impact sample size has.

::: callout-note
To perform the same step multiple times with just one variable changing (in this case: sample size), we can use `for` loops. First we have to define what to iterate through (a vector of sample sizes). Then, we initialize a few list that we store objects in that are created during an iteration:

-   `avg_tbl_age_lst()`: To store average age for specific sample size

-   `avg_tbl_sex_lst()`: To store average sex (proportion) for specific sample size

-   `tbl_sampled_lst()`: To store actual table for sample size (for later use)

To store data from an iteration, we assign it to a list by accessing the list with two square brackets: `lst[["name"]] <- object_to_store`.

There are several other ways to do it (even without loops). But `for` loops are an intuitive way and often times sufficient. You can read more about `for` loops [here](https://www.r-bloggers.com/2015/12/how-to-write-the-first-for-loop-in-r/).
:::

```{r}
# Define vector of sample sizes
sss <- c(10, 50, 500, seq(1000, 1e+4, 500))

# Create empty lists to store average tables in
avg_tbl_age_lst <- list()
avg_tbl_sex_lst <- list()
tbl_sampled_lst <- list()

# Iterate through sample sizes
# ... for sample size in sample sizes ...
for (ss in sss) {
  # sample from population
  X_sampled <- sample_n(X, ss)
  
  # perform random assignment
  D <- rbinom(ss, 1, 0.5)
  
  # combine characteristics and assignment in one table
  tbl_sampled <- X_sampled %>% mutate(treatment = D)
  
  # store in list
  tbl_sampled_lst[[paste(ss)]] <- tbl_sampled
  
  # get average characteristics ...
  # ... for age
  avg_tbl_age <- tbl_sampled %>%
    group_by(treatment) %>%
    summarise(mean_age = mean(age)) %>% 
    ungroup %>% 
    add_column(sample_size = ss,
               variable = "age") %>% 
    pivot_wider(names_from = treatment,
                names_prefix = "D_",
                values_from = mean_age) %>% 
    mutate(delta_abs = abs(D_1 - D_0),
           delta_rel = delta_abs/D_0)
  
  # store table in list
  avg_tbl_age_lst[[paste(ss)]] <- avg_tbl_age
  
  # ... for sex
  avg_tbl_sex <- tbl_sampled %>%
    group_by(treatment) %>%
    summarise(mean_sex = mean(sex)) %>% 
    ungroup %>% 
    add_column(sample_size = ss,
               variable = "sex") %>% 
    pivot_wider(names_from = treatment,
                names_prefix = "D_",
                values_from = mean_sex) %>% 
    mutate(delta_abs = abs(D_1 - D_0),
           delta_rel = delta_abs/D_0)
  
  # store table in list
  avg_tbl_sex_lst[[paste(ss)]] <- avg_tbl_sex
}
```

As you can see in the plot below, group average characteristics converge with increasing sample size. The more units are assigned to either group, the less differences are between the groups and thus, the independence assumption, stating that groups only differ by their treatment status, is fulfilled. But although you need a minimum amount of units, there is not much improvement after increasing the sample size way beyond that (also, the difference is already really small).

```{r}
#| fig-cap: "With increasing sample size, differences between treatment and control group get smaller or are already so small, that they can be ignored."

# Combine tables to one larger table
avg_age <- avg_tbl_age_lst %>% bind_rows()
avg_sex <- avg_tbl_sex_lst %>% bind_rows()
avgs_tbl <- avg_age %>% bind_rows(avg_sex)

# Plot convergence
ggplot(avgs_tbl, aes(x = sample_size, y = delta_abs)) +
  geom_line() +
  facet_wrap(~variable, scales = "free") +
  labs(x = "Sample size", y = "Absolute difference") +
  ggtitle("Absolute difference of characteristics\n between groups by sample size")
```

## Average Treatment Effect

Just because we can, let's just use all of them. That means there should be about \~5'000 units per group. There are many suggested rules and guidelines to choose the right sample size, but for now, we will disregard it as our data is simulated and therefore, we do not have any data problems.

```{r}
#| include: false

# Sample selection ----
ss_selected <- 1e+4
df <- tbl_sampled_lst[[paste(ss_selected)]]
# DO NOT INCLUDE
df_out <- df %>%
  mutate(outcome = 0.2*treatment 
         + 0.01*treatment*age 
         + treatment*sex 
         + rnorm(ss_selected, 2, 3))
```

So far, we have just looked at the covariate balance but have not included the outcome variable. Let's do that now. In the background we simulated the outcome after treatment and added the column `outcome` to our table.

```{r}
# Show data with outcome variable
df_out
```

As already mentioned, having balanced baseline characteristics between treatment and control group allows us to estimate the average treatment effect.

**But how do we calculate the average treatment effect?** We can just take a simple difference in means to estimate it. By the way, groups can be of different group size. It is only important, that they are comparable in their characteristics.

Let's compute the average outcome per group. We see that there seems to be a difference, the average outcome in the treatment group is higher.

```{r}
# Group by treatment group and compute average outcome
df_out %>% 
  group_by(treatment) %>% 
  summarise(mean_outcome = mean(outcome))
```

Generally, it is recommendable to use a linear regression to get an estimate of the treatment effect. You don't have to manually compute the difference and additionally, the output of `lm()` and `summary()` yields information to be used for statistical inference. Then, we see that this effect is in fact highly statistically significant. The effect is equal to the difference of the two values just seen above. Check it out (small differences possible due to rounding)!

```{r}
# Compute ATE with linear regression
lm_ate <- lm(outcome ~ treatment, data = df_out)
summary(lm_ate)
```

One way to present your results to your audience could be a boxplot that on the one hand shows the difference of regressors by group and on the other hand the difference of outcomes. Here we will show the 95% confidence intervals for our estimates and it can be seen that there is a substantial difference between both groups. However, for our independent variables, `age` and `sex` , both groups are very similar.

```{r}
#| layout-nrow: 1
#| fig-cap: "Treatment and control group are similar regarding their characteristics but for the outcome, they are different. Due to the similarity in characteristics, we can ascribe this difference to the treatment."

# Plot independent and and depdent difference
# age (independent)
compare_age <- 
  ggplot(df_out, 
         aes(x = treatment, 
             y = age, 
             color = as.factor(treatment))) +
  stat_summary(geom = "pointrange", 
               fun.data = "mean_se", 
               fun.args = list(mult=1.96),
               show.legend = F) +
  labs(x = NULL, y = "Age", title = "Difference in age")

# sex (independent)
compare_sex <- 
  ggplot(df_out, 
         aes(x = treatment, 
             y = sex, 
             color = as.factor(treatment))) +
  stat_summary(geom = "pointrange", 
               fun.data = "mean_se", 
               fun.args = list(mult=1.96),
               show.legend = F) +
  labs(x = NULL, y = "Sex", title = "Difference in sex")

# outcome (dependent)
compare_outcome <- 
  ggplot(df_out, 
         aes(x = treatment, 
             y = outcome, 
             color = as.factor(treatment))) +
  stat_summary(geom = "pointrange", 
               fun.data = "mean_se", 
               fun.args = list(mult=1.96),
               show.legend = F) +
  labs(x = NULL, y = "Outcome", title = "Difference in outcome")

# Plot age, sex and outcome differences for both groups
compare_age
compare_sex
compare_outcome
```

But why did we not include $age$ and $sex$ into our regression? Because they are similarly distributed across both groups it should not change the treatment effect. But still, they might have an impact on the outcome, as well. Although being similarly distributed in both groups, they can still vary within each group. So let's see what happens if we include them.

Both regressors turn out to be significant. However, as expected, the treatment effect is almost unchanged.

```{r}
# Include other regressors
lm_all <- lm(outcome ~ treatment + age + sex, data = df_out)
summary(lm_all)
```

## Subgroup analysis

The significance of $age$ and $sex$ could also indicate that there are different treatment effects across different levels of both covariates. Then, a so called interaction/moderation effect would be covered behind the statistical coefficients.

A moderation effect expresses different strengths of the treatment for different subgroups. For example older women might benefit relatively more from the treatment and younger males relatively less.

In `R`, we include interaction effects by using either using a product `x1*x2` or a colon `x1:x2`. In fact, when we do that, the interactions are significant and the treatment effect changes substantially.

Note, that now the treatment effect differs for everyone dependent on their age and sex. Now it requires a bit of addition to obtain the treatment effect. Moreover, it is not the $ATE$ anymore, but instead the conditional average treatment effect $CATE$ as it depends on other covariates.

```{r}
# Include interaction
lm_mod <- lm(outcome ~ treatment * age + treatment * sex, data = df_out)
summary(lm_mod)
```

Note also that $R^2$ has increased with each addition to the regression. But why do you think the main treatment effect is not significant anymore?

As the data is simulated, we can check what the true data-generating process is and based on that evaluate what regression equation provides the best solution. Check for yourself what model should be used.

$$
outcome = 0.2*treatment + 0.01*treatment*age + treatment*sex + \epsilon
$$

Again, it shows how crucial theoretical knowledge of the phenomenon you are studying is. Imagine a situation with a high number of regressors. Testing out all potential variables as moderators requires some effort and might even lead to results just due to chance. You should therefore plan your research design and hypotheses beforehand. As a matter of fact, many scientific publications therefore have to define a [pre-analysis plan](https://blogs.worldbank.org/impactevaluations/a-pre-analysis-plan-checklist).

# Conclusion

In this chapter, you should have learned the benefits of randomization. So why not just always randomize treatment objects and make causal claims afterwards? Although there are some fields like medicine, particularly drug trials, that almost fully rely on randomized controlled trials. Other fields, however, cannot rely on RCTs due to a variety of reasons.

For example in social sciences conducting RCTs can be problematic due to high cost or for ethical reasons. One example would be researching the effect of smoking during pregnancy on success of the child later in life. It is clearly unethical to dictate some women to smoke during pregnancy as we already know that it will very likely do damage to both mother and children and we are not interested in the direction of the effect but rather in the magnitude.

Another example would be the effect of implementing a minimum wage on some employees. While the result is not obvious in this case, it is still not fair to pay minimum wage only to a selection of the workforce as it substantially affects their life.

Also, many government programs like e.g. unemployment insurance cannot given only to a random sample of people to identify the effect.

In business context, you are also interested in analyzing past data, that has not been collected using randomized settings. In such cases, researchers need to rely on observational studies to estimate effects. Using our graphical language introduced in the previous chapters, let's illustrate the difference between observational studies and DAGs.

```{r}
#| message: false
#| layout-nrow: 1
#| fig-cap:
#|  - "Observational study"
#|  - "Experimental study"

# Load package to draw DAGs
library(ggdag)

# (1) Observational studies
# define DAG
obs_topic_DAG <- dagify(
  D ~ Z,
  Y ~ Z,
  Y ~ D,
  coords = list(x = c(Y = 3, Z = 2, D = 1),
                y = c(Y = 0, Z = 1, D = 0))
)

# draw DAG and assign to object
obs_dag <- ggdag(obs_topic_DAG, node_size = 10) +
  theme_dag_cds() +
  geom_dag_point(color = ggthemr::swatch()[2]) +
  geom_dag_text(color = "white") +
  geom_dag_edges(edge_color = "white")

# (2) Experimental studies
# define DAG
exp_topic_DAG <- dagify(
  Y ~ Z,
  Y ~ D,
  coords = list(x = c(Y = 3, Z = 2, D = 1),
                y = c(Y = 0, Z = 1, D = 0))
)

# draw DAG and assign to object
exp_dag <- ggdag(exp_topic_DAG) +
  theme_dag_cds() +
  geom_dag_point(color = ggthemr::swatch()[2]) +
  geom_dag_text(color = "white") +
  geom_dag_edges(edge_color = "white")

# Plot both DAGs
obs_dag
exp_dag
```

Observational studies are based only on what a researches observes as opposed to experimental studies where a researcher actively intervenes. In observational studies, one large issue (not the only one) is confounding by other variables. Confounding falsifies our estimate in case we do not control for this variable. Because in many times, we don't know confounders or they are unobserved, estimates from observational studies always rely on additional assumptions and domain knowledge that randomized experiments do not require.

Opposed to that, in RCTs, there is no arrow from the confounder to the treatment assignment. That is because we randomized treatment and therefore, by definition, treatment selection cannot be confounded. In our example that was indicated by the covariate balance across treatment and control group.

All other tools that we will learn in the following chapters try to deal with the issue of isolating causal effects in observational studies by exploiting the underlying causal mechanisms.

# Assignment

Load the dataset `abtest_online.rds`. It is about a randomized experiment run by an online shop. Online shops run a lot of randomized experiments (in business context often called AB-testing), where a randomly selected website visitors are shown a slightly different website than the others. This way, new features can be tested and the final decision to implement a new feature will be based on the results of this test.

Let's imagine the following scenario: you are running an online shop and worry about the cost of your customer service. To reduce the cost, you consider implementing a chatbot that can replace the human customer service. However, you are not sure if that could affect your sales negatively, and therefore you plan an AB-test, where a selection of users is led on a website with a chatbot (treatment group) and the other customers still turn to the human customer service (control group) in case of question. To ensure randomization, you assign treatment based on the last digit of the IP-address.

There are two outcome variables, `y_bin` and `y_num`. The first one shows whether a customer bought and the other how much (in €) he bought. Let's use `y_num` for now.

Other variables included are `mob_dev`being `TRUE` when a user visits the site using a mobile device and `pre_vis` indicating the number of previous visits of a particular user.

After loading the data, perform the following steps:

1.  Check whether the covariates are balanced across the groups. Use a plot to show it.
2.  Run a regression to find the effect of chatbot on sales
3.  Find subgroup-specific effects by including an interaction. Compute a CATE for one exemplary group. A subgroup could be for example mobile users.

::: callout-tip
Bonus: use $purch$ as outcome variable. Note, in that case you cannot use a linear regression as the outcome is either yes or no (or 1 and 0). You have to use a logistic regression using the command `glm(formula, family=binomial(link='logit'), data)`.

**This bonus task is not an assignment you have to submit, but feel free to do it!**
:::

::: callout-warning
## How to submit your solutions!

Please see [here](https://owmork.github.io/causal_ds/submission/submission.html) how you have to successfully submit your solutions. I would recommend you to solve the assignments first in `.R` scripts and in the end convert them to the required format as explained in the submission instructions.
:::
